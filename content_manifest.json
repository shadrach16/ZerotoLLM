{
  "version": 1,
  "courses": [ 
    {
      "id": "course_micrograd",
      "title": "Building Micrograd: Backpropagation from Scratch",
      "thumbnail": "assets/micrograd-thumbnail.jpg",
      "description": "Master the fundamentals of neural networks by building 'micrograd', a tiny Autograd engine, from scratch in Python.",
      "sequence_order": 1,
      "chapters": [
        {
          "id": "micrograd_ch1",
          "title": "The Intuition of Derivatives",
          "video_id": "VMj-3S1tku0",
          "description": "We start by defining the derivative conceptually as the 'rise over run' sensitivity of a function to its inputs. We implement a simple numerical estimation of the derivative for scalar functions. ",
          "start": 0,
          "end": 1149,
          "xp_reward": 30,
          "key_learning_outcomes": [
            "Definition of Derivative (Limit as h->0)",
            "Numerical estimation of slope",
            "Understanding function sensitivity"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the formula for the numerical approximation of a derivative.",
              "template": "def get_derivative(f, x, h=0.0001):\n    # Calculate rise over run\n    return (f(x + h) - ___) / ___",
              "solution": "def get_derivative(f, x, h=0.0001):\n    # Calculate rise over run\n    return (f(x + h) - f(x)) / h",
              "hints": [
                "Subtract the function value at x from the value at x+h.",
                "Divide by the step size h."
              ]
            },
            {
              "type": "quiz",
              "instruction": "If a function f(x) has a derivative of -3.0 at x=2.0, what does this imply?",
              "options": [
                "Increasing x slightly will decrease the output.",
                "Increasing x slightly will increase the output.",
                "The function is flat at x=2.0."
              ],
              "solution": "Increasing x slightly will decrease the output.",
              "hints": [
                "A negative slope means the function goes down as you go right."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch2",
          "title": "The Value Object & Visualization",
          "video_id": "VMj-3S1tku0",
          "description": "We define the core `Value` class to wrap scalar numbers, allowing us to track the history of operations for the computation graph. We implement `__add__` and `__mul__` to overload Python operators.",
          "start": 1149,
          "end": 1930,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Creating a Wrapper Class for scalars",
            "Operator Overloading (__add__, __mul__)",
            "Building the computation graph structure (children, ops)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Complete the Value class initialization to track graph connectivity.",
              "template": "class Value:\n    def __init__(self, data, _children=(), _op=''):\n        self.data = data\n        self.grad = 0.0\n        # Store the previous nodes to build the graph\n        self._prev = set(___)\n        self._op = _op",
              "solution": "_children",
              "hints": [
                "We need to convert the tuple of children into a set for the previous nodes."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the addition operator overloading.",
              "template": "def __add__(self, other):\n    # Create a new Value that is the sum of self and other\n    out = Value(self.data + other.data, (self, other), '+')\n    return out",
              "solution": "def __add__(self, other):\n    out = Value(self.data + other.data, (self, other), '+')\n    return out"
            }
          ]
        },
        {
          "id": "micrograd_ch3",
          "title": "Manual Backpropagation: The Basics",
          "video_id": "VMj-3S1tku0",
          "description": "We begin manually calculating derivatives for a simple expression graph. We discover how addition nodes 'route' gradients and multiplication nodes 'switch' gradients based on input values.",
          "start": 1930,
          "end": 2634,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Local Derivatives for Addition and Multiplication",
            "Routing vs Switching Gradients",
            "Understanding `grad` accumulation"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "In the expression `d = a + b`, if `dL/dd = 2.0`, what is `dL/da`?",
              "options": [
                "2.0 (The addition node distributes the gradient equally)",
                "1.0 (It divides the gradient)",
                "0.0"
              ],
              "solution": "2.0 (The addition node distributes the gradient equally)",
              "hints": [
                "The local derivative of addition is 1.0.",
                "Multiply global gradient by local derivative."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "For `d = a * b`, the gradient with respect to `a` depends on `b`.",
              "template": "# d = a * b\n# grad_a = grad_d * local_derivative\n# local_derivative of (a*b) with respect to a is ___\ngrad_a = grad_d * b.data",
              "solution": "b.data",
              "hints": [
                "Differentiation of ax with respect to x is a."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch4",
          "title": "The Chain Rule & Optimization",
          "video_id": "VMj-3S1tku0",
          "description": "We formalize the backpropagation logic using the Chain Rule from calculus, multiplying local derivatives by global gradients. We then perform a single manual optimization step to reduce the output.",
          "start": 2634,
          "end": 3172,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "The Chain Rule Formula",
            "Recursive application of gradients",
            "Nudging inputs to minimize/maximize output"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Order the logic for the Chain Rule as explained in the video.",
              "solution": "Find the derivative of the output w.r.t the current node\nMultiply it by the local derivative of the current node w.r.t input\nResult is the derivative of the output w.r.t the input",
              "lines": [
                "Multiply it by the local derivative of the current node w.r.t input",
                "Find the derivative of the output w.r.t the current node",
                "Result is the derivative of the output w.r.t the input"
              ],
              "hints": [
                "Start with the gradient coming from 'above' (the output)."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "To minimize the output `L`, we should adjust input `a` in the direction ___ to the gradient.",
              "template": "# Gradient Descent Step\n# a.data += step_size * (___ * a.grad)",
              "solution": "-1.0",
              "hints": [
                "The gradient points in the direction of increase.",
                "We want to go the opposite way."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch5",
          "title": "Backpropagating a Neuron",
          "video_id": "VMj-3S1tku0",
          "description": "We build a single Neuron model and manually backpropagate gradients through the hyperbolic tangent activation function.",
          "start": 3172,
          "end": 4142,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Structure of a Neuron (Weights, Bias, Activation)",
            "Derivative of tanh (1 - t^2)",
            "Backpropagating through composite functions"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the derivative calculation for the Tanh activation function, assuming `t` is the Tanh output.",
              "template": "def tanh_backward(t, grad_output):\n    # d/dx tanh(x) = 1 - tanh(x)^2\n    local_derivative = 1 - (t ** ___)\n    return grad_output * local_derivative",
              "solution": "2",
              "hints": [
                "It is one minus the square of the output."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why was the gradient for `w2` zero in the example shown?",
              "options": [
                "Because the input `x2` was zero, killing the gradient flow during multiplication.",
                "Because the weight was initialized to zero.",
                "Because tanh squashed it to zero."
              ],
              "solution": "Because the input `x2` was zero, killing the gradient flow during multiplication.",
              "hints": [
                "In multiplication d(w*x)/dw = x. If x is 0, what is the derivative?"
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch6",
          "title": "Automating Gradients",
          "video_id": "VMj-3S1tku0",
          "description": "We remove the manual work by implementing `_backward` closures for each operation and using Topological Sort to call them in the correct order automatically.",
          "start": 4142,
          "end": 4948,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Closures for backward passes",
            "Topological Sort for graph traversal",
            "The `backward()` method"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Arrange the steps for the automatic backward pass function.",
              "solution": "topo = build_topological_sort(self)\nself.grad = 1.0\nfor node in reversed(topo):\n    node._backward()",
              "lines": [
                "self.grad = 1.0",
                "for node in reversed(topo):\n    node._backward()",
                "topo = build_topological_sort(self)"
              ],
              "hints": [
                "We need the graph order first.",
                "We must initialize the gradient of the root node before propagating.",
                "We traverse in reverse topological order."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Define the backward closure for addition inside `__add__`.",
              "template": "def _backward():\n    self.grad += 1.0 * out.grad\n    other.grad += ___ * out.grad",
              "solution": "1.0",
              "hints": [
                "Addition distributes the gradient equally to both parents."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch7",
          "title": "Refining the Engine: Bugs & Powers",
          "video_id": "VMj-3S1tku0",
          "description": "We identify and fix a critical bug where gradients were being overwritten instead of accumulated. We then implement subtraction, division, and power operations to handle complex expressions.",
          "start": 4948,
          "end": 5971,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "The Gradient Accumulation Bug (+= vs =)",
            "Implementing Power Rule (x^k)",
            "Implementing Division as x * y^-1"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What happens if a variable is used multiple times in a graph (e.g., `b = a + a`) and we use `=` instead of `+=` for gradients?",
              "options": [
                "The gradient is incorrect because it only keeps the last branch's contribution.",
                "The gradient causes an infinite loop.",
                "Nothing, it works fine."
              ],
              "solution": "The gradient is incorrect because it only keeps the last branch's contribution.",
              "hints": [
                "Gradients from different paths must sum up (multivariate chain rule)."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the backward pass for the Power operation (x^k).",
              "template": "def _backward():\n    # d/dx (x^k) = k * x^(k-1)\n    self.grad += (other * self.data ** (other - 1)) * ___",
              "solution": "out.grad",
              "hints": [
                "Don't forget to multiply by the incoming global gradient from the output."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch8",
          "title": "PyTorch & Neural Network Modules",
          "video_id": "VMj-3S1tku0",
          "description": "We compare our engine to PyTorch's API and build higher-level classes: `Neuron`, `Layer`, and `MLP` (Multi-Layer Perceptron) to mimic deep learning libraries.",
          "start": 5971,
          "end": 6664,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "PyTorch Tensor API alignment",
            "Defining a Neuron class",
            "Defining an MLP (Multi-Layer Perceptron) class"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the forward pass for a single Neuron.",
              "template": "def __call__(self, x):\n    # w * x + b\n    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n    out = act.tanh()\n    return ___",
              "solution": "out",
              "hints": [
                "Simply return the activated output."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "An MLP is a sequence of Layers.",
              "template": "class MLP(Module):\n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(___)\n        return x",
              "solution": "x",
              "hints": [
                "We pass the output of one layer as input to the next."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch9",
          "title": "Loss & Parameters",
          "video_id": "VMj-3S1tku0",
          "description": "We define a Mean Squared Error (MSE) loss function to measure performance and implement a method to recursively collect all parameters (weights and biases) from the network.",
          "start": 6664,
          "end": 7272,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Mean Squared Error (MSE) Loss formula",
            "Recursively collecting parameters",
            "Purpose of Loss functions"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the MSE loss for a single prediction and target.",
              "template": "diff = prediction - target\nloss = diff ** ___\n# In a real batch, we would average this",
              "solution": "2",
              "hints": [
                "MSE stands for Mean SQUARED Error."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Collect parameters from all neurons in a layer.",
              "template": "class Layer(Module):\n    def parameters(self):\n        return [p for neuron in self.neurons for p in neuron.___()]",
              "solution": "parameters",
              "hints": [
                "Call the parameters method of the individual neuron."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch10",
          "title": "The Training Loop",
          "video_id": "VMj-3S1tku0",
          "description": "We implement the full Gradient Descent loop: Forward pass, Zero Gradients, Backward pass, and Update. We debug a common issue where gradients accumulate incorrectly across steps.",
          "start": 7272,
          "end": 8043,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Gradient Descent Steps (Forward, Backward, Update)",
            "The necessity of `zero_grad`",
            "Learning Rate tuning"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Order the steps of a single training iteration.",
              "solution": "loss = model(inputs) # Forward pass\nmodel.zero_grad()\nloss.backward()\nfor p in model.parameters():\n    p.data += -0.01 * p.grad",
              "lines": [
                "loss.backward()",
                "model.zero_grad()",
                "loss = model(inputs) # Forward pass",
                "for p in model.parameters():\n    p.data += -0.01 * p.grad"
              ],
              "hints": [
                "Calculate loss first.",
                "Clear old gradients before calculating new ones.",
                "Backpropagate.",
                "Update weights."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why did the network train too fast and then become unstable before adding `zero_grad()`?",
              "options": [
                "The gradients were accumulating every step, effectively increasing the step size uncontrollably.",
                "The learning rate was set to 100.0.",
                "The random initialization was lucky."
              ],
              "solution": "The gradients were accumulating every step, effectively increasing the step size uncontrollably.",
              "hints": [
                "Remember the `+=` bug fix? It applies across training steps too if not cleared."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch11",
          "title": "Conclusion & Real-World Application",
          "video_id": "VMj-3S1tku0",
          "description": "We wrap up by reviewing the full code structure, looking at a more complex binary classification demo, and diving into the actual PyTorch codebase to find the `tanh` implementation.",
          "start": 8043,
          "end": 8751,
          "xp_reward": 30,
          "key_learning_outcomes": [
            "Micrograd vs Production Libraries (PyTorch)",
            "Understanding Stride/Offset in Tensors (Briefly)",
            "Real-world complexity of autograd kernels"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "When looking at the real PyTorch code, why was the `tanh` implementation so hard to find?",
              "options": [
                "It is buried in complex dispatch files involving CPU/GPU kernels and optimizations.",
                "It doesn't exist; PyTorch uses magic.",
                "It was in the root folder."
              ],
              "solution": "It is buried in complex dispatch files involving CPU/GPU kernels and optimizations.",
              "hints": [
                "Production libraries prioritize efficiency and hardware support over readability."
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course_makemore_bigram",
      "title": "Building Makemore: The Bigram Language Model",
      "thumbnail": "assets/makemore-thumbnail.jpg",
      "description": "Build a character-level language model from scratch. Start with a probabilistic bigram model using frequency counts, then evolve it into a neural network using PyTorch, covering tensors, broadcasting, softmax, and gradient descent.",
      "sequence_order": 2,
      "chapters": [
        {
          "id": "makemore_ch1",
          "title": "Bigrams & Data Exploration",
          "video_id": "PaCmpygFfXo",
          "description": "We begin by exploring the `names.txt` dataset and understanding the core concept of a Bigram Language Model: predicting the next character based solely on the previous one. We implement a simple counting mechanism using Python dictionaries.",
          "start": 0,
          "end": 765,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Concept of Character-Level Language Models",
            "Iterating over strings to form Bigrams",
            "Using `zip` for sliding windows",
            "Counting frequencies with Python dictionaries"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Use `zip` to iterate over a string `w` and create bigrams (consecutive character pairs).",
              "template": "w = \"emma\"\n# Create pairs (e, m), (m, m), (m, a)\nfor ch1, ch2 in zip(w, ___):\n    print(ch1, ch2)",
              "solution": "w[1:]",
              "hints": [
                "You want to zip the string with a version of itself shifted by one index."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Count occurrences of bigrams in a dictionary `b`.",
              "template": "bigram = (ch1, ch2)\n# Get current count, default to 0 if not found, then add 1\nb[bigram] = b.get(bigram, ___) + 1",
              "solution": "0",
              "hints": [
                "The default value for a counter should be zero."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch2",
          "title": "Tensors & Visualizing Counts",
          "video_id": "PaCmpygFfXo",
          "description": "We migrate from Python dictionaries to PyTorch Tensors for efficiency. We build a 2D integer tensor to store counts and create mappings (`stoi` and `itos`) to convert between characters and integer indices. ",
          "start": 765,
          "end": 1442,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Creating PyTorch Tensors (`torch.zeros`)",
            "String-to-Integer (`stoi`) and Integer-to-String (`itos`) mappings",
            "Indexing into 2D Tensors"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Initialize a 27x27 tensor of integers to store the counts.",
              "template": "import torch\n# We need 27 characters (26 letters + 1 special token)\nN = torch.zeros((27, 27), dtype=torch.___)",
              "solution": "int32",
              "hints": [
                "We are storing counts, so we need an integer type.",
                "The video suggests int32."
              ]
            },
            {
              "type": "code",
              "instruction": "Create the `stoi` (string to integer) mapping for lowercase letters.",
              "template": "chars = sorted(list(set(''.join(words))))\n# Map characters to integers starting from 1 (reserving 0 for special token)\nstoi = {s:___ for i, s in enumerate(chars)}",
              "solution": "i+1",
              "hints": [
                "Ensure the index `i` is shifted by 1."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch3",
          "title": "Sampling & Generators",
          "video_id": "PaCmpygFfXo",
          "description": "We convert raw counts into probability distributions and use `torch.multinomial` to sample new characters. We also learn about `torch.Generator` to ensure our results are deterministic and reproducible.",
          "start": 1442,
          "end": 2177,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Converting counts to probabilities",
            "Using `torch.multinomial` for sampling",
            "Deterministic randomness with `torch.Generator`"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why do we use `torch.Generator` with a manual seed?",
              "options": [
                "To ensure the random sampling is reproducible every time we run the code.",
                "To make the code run faster.",
                "To automatically optimize the tensor operations."
              ],
              "solution": "To ensure the random sampling is reproducible every time we run the code.",
              "hints": [
                "It allows us to get the exact same 'random' numbers."
              ]
            },
            {
              "type": "code",
              "instruction": "Sample 1 index from a probability distribution `p`.",
              "template": "g = torch.Generator().manual_seed(2147483647)\n# p is a vector of probabilities\nix = torch.multinomial(p, num_samples=___, replacement=True, generator=g).item()",
              "solution": "1",
              "hints": [
                "We only want a single next character index."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch4",
          "title": "Broadcasting & Vectorization",
          "video_id": "PaCmpygFfXo",
          "description": "We optimize the normalization step using vectorization. This chapter dives deep into PyTorch's Broadcasting semantics, a powerful but dangerous feature that can introduce silent bugs if dimensions aren't managed correctly.",
          "start": 2177,
          "end": 3014,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Vectorized row-wise summation",
            "The `keepdim=True` argument",
            "PyTorch Broadcasting Rules (Align right, create dimension 1)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Calculate the sum of each row (dimension 1) while keeping the dimension to allow for broadcasting.",
              "template": "# P is a (27, 27) tensor\n# We want a (27, 1) vector of sums\nP_sum = P.sum(dim=1, keepdim=___)",
              "solution": "True",
              "hints": [
                "If we don't keep the dimension, it squeezes to (27,), which might broadcast incorrectly as a row vector."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Order the steps to correctly normalize the probability matrix P.",
              "solution": "P = N.float()\nP_sum = P.sum(1, keepdim=True)\nP = P / P_sum",
              "lines": [
                "P = P / P_sum",
                "P_sum = P.sum(1, keepdim=True)",
                "P = N.float()"
              ],
              "hints": [
                "Convert to float first.",
                "Calculate the sum.",
                "Divide."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch5",
          "title": "Maximum Likelihood & Loss",
          "video_id": "PaCmpygFfXo",
          "description": "We introduce the concept of Loss to evaluate the model's quality. We derive the Negative Log Likelihood (NLL) and discuss Model Smoothing to handle infinite loss caused by zero-probability events.",
          "start": 3014,
          "end": 3777,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Likelihood vs Log Likelihood",
            "Negative Log Likelihood (NLL) as a Loss Function",
            "Model Smoothing (Fake Counts)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Calculate the Negative Log Likelihood (NLL) loss.",
              "template": "# prob is the probability assigned to the correct character\nlog_prob = torch.log(prob)\nloss = -___",
              "solution": "log_prob",
              "hints": [
                "We want to minimize the negative of the log probability."
              ]
            },
            {
              "type": "quiz",
              "instruction": "What is the purpose of 'Model Smoothing' (adding counts to N)?",
              "options": [
                "To prevent zero probabilities, which cause infinite loss.",
                "To make the model train faster.",
                "To reduce the number of parameters."
              ],
              "solution": "To prevent zero probabilities, which cause infinite loss.",
              "hints": [
                "Log of zero is negative infinity."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch6",
          "title": "The Neural Network Approach",
          "video_id": "PaCmpygFfXo",
          "description": "We shift paradigms from counting to Neural Networks. We prepare the dataset for the NN using One-Hot Encoding and implement the first Linear Layer using Matrix Multiplication. ",
          "start": 3777,
          "end": 4726,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "One-Hot Encoding inputs",
            "Matrix Multiplication (@ operator)",
            "Initializing weights randomly"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "One-hot encode a tensor of integers `xs` and cast it to float.",
              "template": "import torch.nn.functional as F\n# xs contains integers. Encode to 27 classes.\nxenc = F.one_hot(xs, num_classes=27).___()",
              "solution": "float",
              "hints": [
                "Neural networks expect floating point inputs, but one_hot returns integers by default."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Perform the linear transformation (Matrix Multiplication).",
              "template": "# xenc is (5, 27), W is (27, 27)\nlogits = xenc ___ W",
              "solution": "@",
              "hints": [
                "Use the Python operator for matrix multiplication."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch7",
          "title": "Logits & Softmax",
          "video_id": "PaCmpygFfXo",
          "description": "We interpret the output of the linear layer as 'logits' (log-counts). We apply the Softmax function (exponentiation followed by normalization) to convert logits into valid probability distributions.",
          "start": 4726,
          "end": 5749,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Interpretation of Logits",
            "The Softmax Function (exp -> normalize)",
            "Numerical stability of probabilities"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Implement the Softmax function on the logits.",
              "solution": "counts = logits.exp()\nprobs = counts / counts.sum(1, keepdims=True)",
              "lines": [
                "probs = counts / counts.sum(1, keepdims=True)",
                "counts = logits.exp()"
              ],
              "hints": [
                "First, exponentiate the logits to get 'fake counts'.",
                "Then, normalize the counts to sum to 1."
              ]
            },
            {
              "type": "quiz",
              "instruction": "If the logits are negative numbers, what happens when we apply `.exp()`?",
              "options": [
                "They become positive numbers between 0 and 1.",
                "They become negative numbers.",
                "They become undefined."
              ],
              "solution": "They become positive numbers between 0 and 1.",
              "hints": [
                "e^x for x < 0 is a small positive number."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch8",
          "title": "Optimization: Gradient Descent",
          "video_id": "PaCmpygFfXo",
          "description": "We implement the full training loop. We calculate the vectorized loss, perform the backward pass (Backpropagation), and update the weights to minimize the loss. ",
          "start": 5749,
          "end": 6469,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Vectorized Loss Calculation",
            "The Backward Pass (`loss.backward()`)",
            "Gradient Descent Update (`data += -lr * grad`)"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Extract the probabilities assigned to the correct targets for the loss calculation.",
              "template": "# probs is (5, 27), ys is (5,)\n# We want to pick the probability for the correct label in each row\nloss_probs = probs[torch.arange(5), ___]",
              "solution": "ys",
              "hints": [
                "Use the target labels `ys` as the column indices."
              ]
            },
            {
              "type": "code",
              "instruction": "Perform the weight update step.",
              "template": "# W is the weight tensor\nlearning_rate = 0.1\nW.data += -learning_rate * ___",
              "solution": "W.grad",
              "hints": [
                "We move in the opposite direction of the gradient."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch9",
          "title": "Regularization & Summary",
          "video_id": "PaCmpygFfXo",
          "description": "We discuss the connection between 'Model Smoothing' in the counting approach and 'Weight Regularization' in the neural network. We conclude by sampling from the trained neural network.",
          "start": 6469,
          "end": 7064,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Model Smoothing as Weight Decay",
            "Sampling from the Neural Network",
            "Equivalence of Counting and Single-Layer NN"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "How does forcing weights `W` towards zero act as regularization (smoothing)?",
              "options": [
                "Zero weights lead to zero logits, which result in a uniform probability distribution.",
                "Zero weights make the model output zeros.",
                "It prevents the model from calculating gradients."
              ],
              "solution": "Zero weights lead to zero logits, which result in a uniform probability distribution.",
              "hints": [
                "exp(0) = 1. If all logits are 0, all counts are 1."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Before the backward pass in the training loop, what must we do to the gradients?",
              "template": "# Reset gradients to zero\nW.grad = ___",
              "solution": "None",
              "hints": [
                "In PyTorch, we can set `.grad` to this special value to indicate no gradient."
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course_makemore_mlp",
      "title": "Building Makemore: The Multi-Layer Perceptron",
      "thumbnail": "assets/makemore-mlp-thumbnail.jpg",
      "description": "Upgrade your language model from a simple bigram to a Multi-Layer Perceptron (MLP) following the Bengio et al. 2003 paper. Master embeddings, tensor internals, and proper training methodology.",
      "sequence_order": 3,
      "chapters": [
        {
          "id": "makemore_mlp_ch1",
          "title": "Context, Dataset & Embeddings",
          "video_id": "TCH_1BHY58I",
          "description": "We explore the limitations of n-gram models and introduce the Neural Probabilistic Language Model (Bengio et al. 2003). We build a dataset with a sliding context window and implement the first layer of the network: the Embedding Lookup Table. ",
          "start": 0,
          "end": 1115,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "The curse of dimensionality in n-gram models",
            "Building a sliding window dataset (X, Y)",
            "Implementing character embeddings using matrix indexing"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why does the table-based n-gram approach fail as we increase the context length (e.g., looking back 10 characters)?",
              "options": [
                "The table size grows exponentially, resulting in sparse counts and overfitting.",
                "Computers cannot handle tables larger than 27x27.",
                "It becomes impossible to tokenize the characters."
              ],
              "solution": "The table size grows exponentially, resulting in sparse counts and overfitting.",
              "hints": [
                "Think about how many possible combinations of 10 characters exist (27^10)."
              ]
            },
            {
              "type": "code",
              "instruction": "Construct the input dataset `X` and labels `Y` for a block size of 3.",
              "template": "block_size = 3\nX, Y = [], []\ncontext = [0] * block_size\nfor ch in text:\n    ix = stoi[ch]\n    X.append(context)\n    Y.append(___)\n    context = context[1:] + [___]",
              "solution": "ix",
              "hints": [
                "Y contains the current character index.",
                "Update the context by appending the new index."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Implement the embedding lookup. `C` is the embedding matrix, `X` is the tensor of input indices.",
              "template": "# PyTorch allows indexing with tensors\n# If X is (32, 3) and C is (27, 2)\n# We want the output to be (32, 3, 2)\nemb = C[___]",
              "solution": "X",
              "hints": [
                "You can pass the index tensor directly into the embedding matrix."
              ]
            }
          ]
        },
        {
          "id": "makemore_mlp_ch2",
          "title": "Tensor Internals & The Hidden Layer",
          "video_id": "TCH_1BHY58I",
          "description": "We implement the hidden layer of the MLP. Crucially, we dive deep into PyTorch tensor internals (`storage` vs `view`) to efficiently flatten our input dimensions without copying memory. ",
          "start": 1115,
          "end": 1969,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Efficient reshaping with `.view()` vs `.cat()`",
            "PyTorch Tensor Internals: Storage vs View",
            "Implementing the hidden layer calculation ($tanh(XW+b)$)"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What is the primary advantage of using `.view()` compared to `torch.cat()` when reshaping tensors?",
              "options": [
                "`.view()` does not copy memory; it just changes how the underlying storage is interpreted.",
                "`.view()` automatically calculates gradients.",
                "`.view()` sorts the data elements."
              ],
              "solution": "`.view()` does not copy memory; it just changes how the underlying storage is interpreted.",
              "hints": [
                "Think about efficiency and memory allocation."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Reshape the embedding tensor `emb` of shape (32, 3, 2) to (32, 6) to feed into the linear layer, using the most efficient method.",
              "solution": "# emb.shape is (32, 3, 2)\n# We want to flatten the last two dimensions\nflattened = emb.view(emb.shape[0], 6)",
              "lines": [
                "flattened = emb.view(emb.shape[0], 6)",
                "flattened = torch.cat(torch.unbind(emb, 1), 1)",
                "flattened = emb.storage()"
              ],
              "hints": [
                "Avoid creating new tensors if possible."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Calculate the hidden states `h`. Remember to apply the non-linearity.",
              "template": "# emb_view is the flattened input (N, inputs)\n# W1 and b1 are weights and bias\npre_activation = emb_view @ W1 + b1\nh = torch.___(pre_activation)",
              "solution": "tanh",
              "hints": [
                "The Bengio paper and our implementation use the hyperbolic tangent function."
              ]
            }
          ]
        },
        {
          "id": "makemore_mlp_ch3",
          "title": "Optimization & Training Loop",
          "video_id": "TCH_1BHY58I",
          "description": "We professionalize the training loop. We replace our manual loss calculation with `F.cross_entropy` for numerical stability, implement minibatch training for speed, and use a learning rate finder to tune hyperparameters.",
          "start": 1969,
          "end": 3200,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Advantages of `F.cross_entropy` (LogSumExp trick)",
            "Implementing Minibatches",
            "Finding a good learning rate using an exponent scan"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why is `F.cross_entropy(logits, targets)` preferred over manually calculating `softmax` then `nll_loss`?",
              "options": [
                "It uses the LogSumExp trick for numerical stability and efficient backward passes.",
                "It is the only way to calculate loss in PyTorch.",
                "It automatically tunes the learning rate."
              ],
              "solution": "It uses the LogSumExp trick for numerical stability and efficient backward passes.",
              "hints": [
                "Think about what happens if exponentials get very large (overflow)."
              ]
            },
            {
              "type": "code",
              "instruction": "Select a minibatch of indices `ix`.",
              "template": "batch_size = 32\n# X is the training data tensor\n# Generate 32 random indices between 0 and len(X)\nix = torch.randint(0, ___, (batch_size,))",
              "solution": "X.shape[0]",
              "hints": [
                "You need the upper bound of the random integer range."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Construct the list of learning rates to scan exponentially.",
              "template": "# Create 1000 exponents between -3 and 0\nlre = torch.linspace(-3, 0, 1000)\n# Calculate actual learning rates\nlrs = 10 ** ___",
              "solution": "lre",
              "hints": [
                "10 to the power of the exponent."
              ]
            }
          ]
        },
        {
          "id": "makemore_mlp_ch4",
          "title": "Methodology: Splits & Sampling",
          "video_id": "TCH_1BHY58I",
          "description": "We discuss proper machine learning methodology: splitting data into Train, Validation, and Test sets to detect overfitting. We scale up the network parameters and conclude by generating samples from our trained MLP.",
          "start": 3200,
          "end": 4539,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Train/Validation/Test Split methodology",
            "Detecting Overfitting vs Underfitting",
            "Sampling from the MLP",
            "Visualizing Embeddings"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If your training loss is very low but your validation loss is very high, what is likely happening?",
              "options": [
                "Overfitting: The model is memorizing the training data but not generalizing.",
                "Underfitting: The model is too simple to learn the pattern.",
                "The learning rate is too low."
              ],
              "solution": "Overfitting: The model is memorizing the training data but not generalizing.",
              "hints": [
                "The model performs great on data it has seen, but fails on new data."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "When sampling, we convert the network output logits into probabilities using this function.",
              "template": "# logits is the output of the final layer\nprobs = F.___(logits, dim=1)",
              "solution": "softmax",
              "hints": [
                "This function ensures the outputs sum to 1 and are positive."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Order the steps to sample a single character from the model.",
              "solution": "logits = model(context)\nprobs = F.softmax(logits, dim=1)\nix = torch.multinomial(probs, num_samples=1).item()\ncontext = context[1:] + [ix]",
              "lines": [
                "probs = F.softmax(logits, dim=1)",
                "context = context[1:] + [ix]",
                "ix = torch.multinomial(probs, num_samples=1).item()",
                "logits = model(context)"
              ],
              "hints": [
                "Forward pass -> Probability -> Sample Index -> Update Context."
              ]
            }
          ]
        }
      ]
    },{
      "id": "course_makemore_batchnorm",
      "title": "Makemore: Initialization & Batch Normalization",
      "thumbnail": "assets/makemore-batchnorm-thumbnail.jpg",
      "description": "Deep dive into the 'black magic' of training deep neural networks. Learn how to diagnose training issues, properly initialize weights (Kaiming Init), and implement Batch Normalization from scratch to stabilize training.",
      "sequence_order": 4,
      "chapters": [
        {
          "id": "makemore_bn_ch1",
          "title": "Diagnosing Initialization",
          "video_id": "P6sfmUTpUmc",
          "description": "We analyze the initial loss of the network and realize it is 'confidently wrong'.  We fix this by scaling down the output weights to ensure a uniform probability distribution at the start.",
          "start": 0,
          "end": 779,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Calculating expected initial loss (-log(1/vocab_size))",
            "The 'Hockey Stick' loss curve phenomenon",
            "Initializing output logits to be small/uniform"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If you have a vocabulary of 27 characters and initialize your network correctly, what should the initial loss roughly be?",
              "options": [
                "Approximately 3.3 (-log(1/27))",
                "Approximately 27.0",
                "Exactly 0.0"
              ],
              "solution": "Approximately 3.3 (-log(1/27))",
              "hints": [
                "It should be the negative log likelihood of a uniform distribution."
              ]
            },
            {
              "type": "code",
              "instruction": "Scale down the weights `W2` and biases `b2` of the final layer to ensure logits are close to zero at initialization.",
              "template": "# W2 is shape (n_hidden, vocab_size), b2 is (vocab_size)\nW2 = torch.randn((n_hidden, vocab_size)) * ___\nb2 = torch.randn(vocab_size) * ___",
              "solution": "W2 = torch.randn((n_hidden, vocab_size)) * 0.01\nb2 = torch.randn(vocab_size) * 0",
              "hints": [
                "Multiply weights by a small number (e.g., 0.01).",
                "Set biases to zero."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch2",
          "title": "Activations & The Vanishing Gradient",
          "video_id": "P6sfmUTpUmc",
          "description": "We visualize the hidden layer activations and discover they are saturated at -1 and 1. We explore how this causes the 'Vanishing Gradient' problem for Tanh units and discuss the concept of 'Dead Neurons' in ReLU networks.",
          "start": 779,
          "end": 1673,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Visualizing activation histograms",
            "Tanh derivative property (1 - t^2)",
            "The problem of saturated activations stopping backprop"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If a Tanh neuron's output is 1.0 or -1.0, what happens to the gradient flowing through it during backpropagation?",
              "options": [
                "It becomes zero (destroyed).",
                "It becomes 1 (passed through).",
                "It becomes infinite (exploded)."
              ],
              "solution": "It becomes zero (destroyed).",
              "hints": [
                "The derivative of tanh(x) is 1 - tanh(x)^2."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Check for saturated neurons. We consider a neuron saturated if its absolute value is close to 1.",
              "template": "h_preact = emb @ W1 + b1\n# Create a boolean tensor where True indicates saturation\nsaturated = h_preact.abs() > ___\n# Check if any neuron is saturated for ALL examples (dead neuron)\ndead_neurons = saturated.all(dim=0).any()",
              "solution": "0.97",
              "hints": [
                "Pick a threshold close to 1, like 0.97 or 0.99."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch3",
          "title": "Kaiming Initialization",
          "video_id": "P6sfmUTpUmc",
          "description": "We implement a principled way to initialize weights to keep activation variance constant throughout the network, known as Kaiming (or He) Initialization.",
          "start": 1673,
          "end": 2440,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "The goal of preserving variance (std=1) across layers",
            "The Kaiming Init formula: gain / sqrt(fan_in)",
            "Gain values for Tanh vs ReLU"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement Kaiming Normal initialization for a Tanh layer.",
              "template": "fan_in = 30 # dimensionality of input\n# Gain for Tanh is usually 5/3\ngain = 5/3\n# Standard deviation should be gain / sqrt(fan_in)\nstd = gain / (fan_in ** ___)\nW1 = torch.randn((fan_in, 200)) * std",
              "solution": "0.5",
              "hints": [
                "Power of 0.5 is the square root."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Arrange the logic explaining why we scale weights by 1/sqrt(fan_in).",
              "solution": "Multiplying inputs by weights increases the variance of the output\nTo counteract this expansion, we must scale down the weights\nThe correct scale factor is 1 over the square root of the number of inputs",
              "lines": [
                "The correct scale factor is 1 over the square root of the number of inputs",
                "Multiplying inputs by weights increases the variance of the output",
                "To counteract this expansion, we must scale down the weights"
              ],
              "hints": [
                "Start with the problem (variance expansion)."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch4",
          "title": "Batch Normalization: Training",
          "video_id": "P6sfmUTpUmc",
          "description": "We introduce the 2015 innovation that stabilized deep networks: Batch Normalization. We implement the layer from scratch, normalizing inputs to be unit Gaussian and then scaling/shifting them.",
          "start": 2440,
          "end": 3240,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Calculating Mean and Variance of a batch",
            "Normalizing inputs: (x - mean) / sqrt(var + eps)",
            "Learnable Scale (Gamma) and Shift (Beta) parameters"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the mean and variance of the pre-activations `hpreact` across the batch dimension (dim 0).",
              "template": "# hpreact shape is (32, 200)\n# We want mean shape to be (1, 200) for broadcasting\nbn_mean = hpreact.mean(dim=0, keepdim=___)\nbn_var = hpreact.var(dim=0, keepdim=___)",
              "solution": "True",
              "hints": [
                "We need to keep the dimensions to allow for proper broadcasting later."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Order the operations inside the Batch Normalization forward pass.",
              "solution": "Calculate batch mean and variance\nNormalize inputs to unit variance (standardization)\nScale and shift using learned parameters (gamma, beta)",
              "lines": [
                "Scale and shift using learned parameters (gamma, beta)",
                "Calculate batch mean and variance",
                "Normalize inputs to unit variance (standardization)"
              ],
              "hints": [
                "You must know the stats before you can normalize."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch5",
          "title": "Batch Normalization: Inference",
          "video_id": "P6sfmUTpUmc",
          "description": "We solve the problem of how to use BatchNorm with single examples at inference time. We introduce running buffers (running_mean, running_var) and update them with momentum.",
          "start": 3240,
          "end": 3890,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Training vs Inference behavior of BatchNorm",
            "Running Mean/Var buffers",
            "Momentum updates for running stats"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why can't we just use the batch statistics during inference (test time)?",
              "options": [
                "We might be processing a single example, so variance would be undefined/zero.",
                "It is too computationally expensive.",
                "The paper says not to."
              ],
              "solution": "We might be processing a single example, so variance would be undefined/zero.",
              "hints": [
                "Statistics require a population. A single example has no mean/var relative to itself."
              ]
            },
            {
              "type": "code",
              "instruction": "Update the running mean using a small momentum (e.g., 0.001).",
              "template": "momentum = 0.001\n# Exponential moving average update\nrunning_mean = (1 - momentum) * running_mean + momentum * ___",
              "solution": "bn_mean",
              "hints": [
                "We mix the old running mean with the current batch mean."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch6",
          "title": "Productionizing: Modules & ResNet",
          "video_id": "P6sfmUTpUmc",
          "description": "We restructure our messy code into PyTorch-style classes (`nn.Module`). We also briefly look at ResNet code to see these same principles (BatchNorm, Conv, ReLU) applied in state-of-the-art architectures.",
          "start": 3890,
          "end": 5211,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Structure of PyTorch `nn.Module`",
            "Implementing `__init__` and `__call__`",
            "Structure of a ResNet block (Conv -> BN -> ReLU)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Complete the initialization of the Linear layer class.",
              "template": "class Linear:\n    def __init__(self, fan_in, fan_out, bias=True):\n        self.weight = torch.randn((fan_in, fan_out)) / (fan_in**0.5)\n        self.bias = torch.zeros(fan_out) if ___ else None",
              "solution": "bias",
              "hints": [
                "Check the boolean argument provided to the constructor."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the Linear layer forward pass in `__call__`.",
              "template": "def __call__(self, x):\n    self.out = x @ self.weight\n    if self.bias is not None:\n        self.out += ___\n    return self.out",
              "solution": "self.bias",
              "hints": [
                "Add the bias if it exists."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch7",
          "title": "Diagnostic Visualizations",
          "video_id": "P6sfmUTpUmc",
          "description": "We create powerful visualization tools to inspect the health of our network: activation histograms, gradient histograms, and the update-to-data ratio. ",
          "start": 5211,
          "end": 6957,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Interpreting Activation Histograms (Checking for saturation)",
            "Checking Gradient Distributions",
            "Update-to-Data Ratio (Ideal: ~1e-3)"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the 'Update to Data' ratio for logging.",
              "template": "# lr is learning rate, grad is gradient, data is parameter value\nupdate = lr * grad.std()\ndata = param.std()\nratio = update / ___\nlog_ratio = ratio.log10()",
              "solution": "data",
              "hints": [
                "We want the ratio of the update size to the parameter size."
              ]
            },
            {
              "type": "quiz",
              "instruction": "If your Update-to-Data ratio is around -3.0 (on a log10 scale), what does this indicate?",
              "options": [
                "The updates are roughly 1/1000th the size of the weights. This is a good sweet spot.",
                "The updates are way too large; the model is exploding.",
                "The updates are essentially zero; the model isn't learning."
              ],
              "solution": "The updates are roughly 1/1000th the size of the weights. This is a good sweet spot.",
              "hints": [
                "10^-3 is 0.001."
              ]
            }
          ]
        }
      ]
    }, 
    {
      "id": "course_makemore_backprop",
      "title": "Makemore: Becoming a Backprop Ninja",
      "thumbnail": "assets/makemore-backprop-thumbnail.jpg",
      "description": "De-mystify deep learning by manually implementing backpropagation from scratch. Move beyond 'loss.backward()' to understand tensor-level gradients, matrix calculus, and analytical simplifications for Cross Entropy and Batch Normalization.",
      "sequence_order": 5,
      "chapters": [
        {
          "id": "makemore_bp_ch1",
          "title": "The Leaky Abstraction of Backprop",
          "video_id": "q8SA3rM6ckI",
          "description": "We establish why manual backpropagation is a crucial skill for debugging neural networks. We set up the Multi-Layer Perceptron (MLP) architecture with Batch Normalization that we will be dissecting.",
          "start": 0,
          "end": 781,
          "xp_reward": 30,
          "key_learning_outcomes": [
            "Historical context of manual backprop (pre-Autograd)",
            "The concept of 'Leaky Abstractions' in deep learning",
            "Setting up the MLP forward pass for manual differentiation"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why does the instructor consider Backpropagation a 'Leaky Abstraction'?",
              "options": [
                "Because you can easily shoot yourself in the foot (e.g., vanishing gradients, dead neurons) if you don't understand the internals.",
                "Because it leaks memory if not handled correctly in C++.",
                "Because it reveals the private data of the training set."
              ],
              "solution": "Because you can easily shoot yourself in the foot (e.g., vanishing gradients, dead neurons) if you don't understand the internals.",
              "hints": [
                "Think about debugging issues like saturated tanh or exploding gradients."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch2",
          "title": "Backprop: Loss to Probabilities",
          "video_id": "q8SA3rM6ckI",
          "description": "We begin the manual backward pass at the very end of the graph. We derive gradients for the Negative Log Likelihood loss, log probabilities, and handling shapes/broadcasting during the backward pass.",
          "start": 781,
          "end": 2011,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Gradient of Mean Loss (-1/N)",
            "Backpropagating through `log(x)` (1/x)",
            "Handling tensor shapes during gradient assignment"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Calculate the gradient of the loss with respect to log-probabilities `dlogprobs` for the correct indices.",
              "template": "# n is batch size\n# We only care about the indices specified by target 'Yb'\ndlogprobs[range(n), Yb] = ___ * (1.0/n)",
              "solution": "-1",
              "hints": [
                "The loss is the NEGATIVE log likelihood."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the backward pass for the log operation `logprobs = probs.log()`.",
              "template": "# dlogprobs is the gradient flowing in\n# d/dx log(x) = 1/x\ndprobs = (1.0 / ___) * dlogprobs",
              "solution": "probs",
              "hints": [
                "Multiply the local derivative (1/input) by the global gradient."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch3",
          "title": "Backprop: Broadcasting & Linear Layers",
          "video_id": "q8SA3rM6ckI",
          "description": "We tackle the complexity of broadcasting in reverse. If a dimension is replicated (broadcasted) in the forward pass, it must be summed in the backward pass. We also derive the gradients for Matrix Multiplication.",
          "start": 2011,
          "end": 3223,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Broadcasting rule: Forward Copy -> Backward Sum",
            "Backpropagating through Matrix Multiplication",
            "Matching shapes to determine transpositions"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If `counts_sum` (shape 32x1) was broadcasted to shape (32x27) during division in the forward pass, how do we calculate its gradient `dcounts_sum`?",
              "options": [
                "Sum the incoming gradient `dcounts` across the broadcasted dimension (dim 1).",
                "Replicate the incoming gradient.",
                "Take the mean of the incoming gradient."
              ],
              "solution": "Sum the incoming gradient `dcounts` across the broadcasted dimension (dim 1).",
              "hints": [
                "The variable was used multiple times (once for each column), so we accumulate the gradients."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Determine the gradient `dh` for the expression `logits = h @ W2 + b2`. `dlogits` is (32, 27), `W2` is (64, 27). `dh` must be (32, 64).",
              "solution": "dh = dlogits @ W2.T",
              "lines": [
                "dh = dlogits @ W2.T",
                "dh = dlogits.T @ W2",
                "dh = W2 @ dlogits"
              ],
              "hints": [
                "Align the inner dimensions: (32, 27) @ (27, 64) results in (32, 64)."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch4",
          "title": "Backprop: Tanh & BatchNorm Decomposition",
          "video_id": "q8SA3rM6ckI",
          "description": "We backpropagate through the Tanh activation function and begin dissecting the Batch Normalization layer into its atomic operations (mean, variance, standardization) to calculate gradients step-by-step.",
          "start": 3223,
          "end": 3912,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Gradient of Tanh: `1 - t**2`",
            "Backpropagating through `max()` and `indices`",
            "Decomposing Batch Norm into differentiable steps"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the gradient for the Tanh activation `h = h_preact.tanh()`.",
              "template": "# h is the output of the tanh function\n# d/dx tanh(x) = 1 - tanh(x)^2\ndh_preact = (1.0 - ___**2) * dh",
              "solution": "h",
              "hints": [
                "The derivative can be expressed in terms of the output `h`."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "When backpropagating through `max()`, the gradient is routed ONLY to the indices that achieved the max value. We use `one_hot` to create a mask.",
              "template": "# dlogit_maxes flows only to the max indices\ndlogits += F.one_hot(indices, num_classes=27) * ___",
              "solution": "dlogit_maxes",
              "hints": [
                "Multiply the mask by the incoming gradient."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch5",
          "title": "Bessel's Correction & Variance",
          "video_id": "q8SA3rM6ckI",
          "description": "We dive into the subtle details of variance calculation, specifically Bessel's Correction (dividing by N-1 vs N), and finish backpropagating through the complex chain of Batch Norm operations.",
          "start": 3912,
          "end": 5191,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Bessel's Correction (Unbiased estimator)",
            "Backpropagating through variance calculation",
            "Handling branching paths in computation graphs"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why does the instructor use `1/(n-1)` instead of `1/n` for variance calculation?",
              "options": [
                "It is the unbiased estimator for population variance (Bessel's correction).",
                "It prevents division by zero.",
                "It makes the tensor shapes align better."
              ],
              "solution": "It is the unbiased estimator for population variance (Bessel's correction).",
              "hints": [
                "This correction matters when sample sizes are small."
              ]
            },
            {
              "type": "code",
              "instruction": "Backpropagate through the centering operation `diff = x - mean`.",
              "template": "# d_diff flows back to x and mean\ndx = d_diff\n# Because mean is broadcasted (replicated) across the batch, we sum\ndmean = -d_diff.sum(___, keepdim=True)",
              "solution": "0",
              "hints": [
                "Sum across the batch dimension (0)."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch6",
          "title": "Analytical Gradients: Cross Entropy",
          "video_id": "q8SA3rM6ckI",
          "description": "We realize that backpropagating through atomic loss operations is inefficient. We derive the analytical gradient for the Softmax + Cross Entropy combined layer, resulting in a significantly simpler and faster formula.",
          "start": 5191,
          "end": 5797,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Analytical simplification of Softmax gradient",
            "The `softmax(logits) - target` formula",
            "Intuition of 'Push and Pull' forces in gradients"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Implement the efficient analytical gradient for Cross Entropy Loss.",
              "solution": "dlogits = F.softmax(logits, 1)\ndlogits[range(n), Yb] -= 1\ndlogits /= n",
              "lines": [
                "dlogits /= n",
                "dlogits[range(n), Yb] -= 1",
                "dlogits = F.softmax(logits, 1)"
              ],
              "hints": [
                "Calculate softmax probabilities first.",
                "Subtract 1 from the correct label indices.",
                "Normalize by batch size."
              ]
            },
            {
              "type": "quiz",
              "instruction": "What is the sum of the gradients in `dlogits` for any single example?",
              "options": [
                "Zero",
                "One",
                "It depends on the loss."
              ],
              "solution": "Zero",
              "hints": [
                "The forces of pushing down incorrect classes and pulling up the correct class equalize."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch7",
          "title": "Analytical Gradients: Batch Norm",
          "video_id": "q8SA3rM6ckI",
          "description": "Similar to Cross Entropy, we replace the messy atomic backprop of Batch Norm with a mathematically derived, streamlined equation. ",
          "start": 5797,
          "end": 6602,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Analytical derivative of Batch Normalization",
            "Computational efficiency of fused kernels",
            "Verifying manual gradients against PyTorch"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "The analytical gradient for Batch Norm involves creating a simplified expression for `dh_preact`. This avoids creating intermediate buffers for mean and variance during the ___ pass.",
              "solution": "backward",
              "hints": [
                "We are optimizing the gradient calculation step."
              ]
            },
            {
              "type": "code",
              "instruction": "Call the custom comparison function to verify your manual gradients.",
              "template": "# cmp(manual_name, manual_tensor, pytorch_tensor)\ncmp('h_preact', dh_preact, ___)",
              "solution": "h_preact.grad",
              "hints": [
                "You compare against the `.grad` attribute populated by PyTorch's autograd."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch8",
          "title": "The Grand Loop: Putting It All Together",
          "video_id": "q8SA3rM6ckI",
          "description": "We assemble the complete training loop, replacing `loss.backward()` entirely with our manual implementations. We verify that the network trains just as well as before.",
          "start": 6602,
          "end": 6923,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Replacing Autograd with manual backprop",
            "Structure of a rigorous training loop",
            "Verification of correctness"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Order the steps of the manual training loop.",
              "solution": "forward_pass()\n# Manual Backprop\nbackprop_cross_entropy()\nbackprop_layers()\noptimizer_step()",
              "lines": [
                "optimizer_step()",
                "forward_pass()",
                "backprop_cross_entropy()",
                "backprop_layers()"
              ],
              "hints": [
                "You must compute the loss (forward) before you can derive gradients (backward)."
              ]
            }
          ]
        }
      ]
    },
      {
      "id": "course_makemore_wavenet",
      "title": "Building Makemore: WaveNet",
      "thumbnail": "assets/makemore-wavenet-thumbnail.jpg",
      "description": "Scale up your character-level language model by implementing a WaveNet-like hierarchical architecture. Learn to modularize code like PyTorch, handle high-dimensional tensor operations, and debug complex batch normalization issues.",
      "sequence_order": 6,
      "chapters": [
        {
          "id": "makemore_wn_ch1",
          "title": "Refactoring & PyTorchification",
          "video_id": "t3YJ5hKiMQ0",
          "description": "We clean up the codebase by organizing layers into classes that mimic the `torch.nn` API (Linear, Embedding, Flatten, Sequential). We also fix the noisy loss plots using tensor reshaping techniques. ",
          "start": 0,
          "end": 1031,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Modularizing neural network layers",
            "Implementing a `Sequential` container",
            "Smoothing plots using tensor views and means"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the `forward` method for a custom `Sequential` container that passes input `x` through a list of `layers`.",
              "template": "class Sequential:\n    def __init__(self, layers):\n        self.layers = layers\n\n    def __call__(self, x):\n        for layer in self.layers:\n            x = ___\n        self.out = x\n        return self.out",
              "solution": "layer(x)",
              "hints": [
                "Iterate through each layer and update x with the output of the layer."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Smooth a noisy loss list by converting it to a tensor, reshaping, and taking the mean.",
              "template": "# lossi is a list of floats\nloss_tensor = torch.tensor(lossi)\n# Reshape into rows of 1000 steps each. -1 infers the number of rows.\nloss_matrix = loss_tensor.view(-1, ___)\n# Take the mean along the rows (dimension 1)\nloss_means = loss_matrix.mean(1)",
              "solution": "1000",
              "hints": [
                "We want to average groups of 1000 steps."
              ]
            }
          ]
        },
        {
          "id": "makemore_wn_ch2",
          "title": "Hierarchical Fusion & WaveNet",
          "video_id": "t3YJ5hKiMQ0",
          "description": "We introduce the WaveNet architecture, which uses a tree-like structure to fuse information progressively rather than squashing it all at once.  We implement `FlattenConsecutive` to handle this hierarchy and explore how matrix multiplication works on high-dimensional tensors.",
          "start": 1031,
          "end": 2261,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Concept of hierarchical information fusion",
            "Matrix multiplication broadcasting on rank > 2 tensors",
            "Implementing `FlattenConsecutive` for grouping tokens"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If you perform matrix multiplication between a tensor of shape (4, 5, 80) and a weight matrix of shape (80, 200), what is the resulting shape?",
              "options": [
                "(4, 5, 200)",
                "(4, 80, 200)",
                "(20, 200)",
                "Error: Dimensions do not match"
              ],
              "solution": "(4, 5, 200)",
              "hints": [
                "PyTorch treats dimensions before the last one as batch dimensions and applies the multiplication to the last dimension."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement `FlattenConsecutive` to reshape input `(B, T, C)` into `(B, T/n, C*n)`, effectively concatenating `n` consecutive elements.",
              "template": "class FlattenConsecutive:\n    def __init__(self, n):\n        self.n = n\n        \n    def __call__(self, x):\n        B, T, C = x.shape\n        # We want to group 'n' elements together in the last dimension\n        # New time dimension is T // n\n        # New channel dimension is C * n\n        x = x.view(B, T // self.n, ___)\n        if x.shape[1] == 1: x = x.squeeze(1)\n        self.out = x\n        return self.out",
              "solution": "C * self.n",
              "hints": [
                "The channels multiply by n because we are stacking n vectors side-by-side."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Arrange the layers to create a single block of the hierarchical network.",
              "solution": "FlattenConsecutive(2)\nLinear(n_embd * 2, n_hidden, bias=False)\nBatchNorm1d(n_hidden)\nTanh()",
              "lines": [
                "BatchNorm1d(n_hidden)",
                "Tanh()",
                "FlattenConsecutive(2)",
                "Linear(n_embd * 2, n_hidden, bias=False)"
              ],
              "hints": [
                "First fuse elements, then project, then normalize, then activate."
              ]
            }
          ]
        },
        {
          "id": "makemore_wn_ch3",
          "title": "Debugging BatchNorm & Scaling",
          "video_id": "t3YJ5hKiMQ0",
          "description": "We identify and fix a critical bug in our custom `BatchNorm1d` layer where it was averaging over the wrong dimensions for 3D inputs. We then scale up the network parameters to beat the baseline performance.",
          "start": 2261,
          "end": 3381,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Debugging tensor dimension issues",
            "Adapting BatchNorm for (Batch, Sequence, Feature) shapes",
            "Experimental mindset in Deep Learning"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What was the bug in the original `BatchNorm1d` implementation when passed a 3D input (Batch, Sequence, Channels)?",
              "options": [
                "It calculated the mean only over the Batch dimension (dim 0), treating the Sequence dimension as independent batches.",
                "It calculated the mean over the Channels dimension.",
                "It failed to calculate gradients."
              ],
              "solution": "It calculated the mean only over the Batch dimension (dim 0), treating the Sequence dimension as independent batches.",
              "hints": [
                "We want a single mean per channel, aggregated over both Batch AND Sequence elements."
              ]
            },
            {
              "type": "code",
              "instruction": "Fix the mean calculation in BatchNorm to handle both 2D and 3D inputs correctly.",
              "template": "# x is the input tensor\nif x.ndim == 2:\n    dim = 0\nelif x.ndim == 3:\n    # We want to average over Batch (0) and Time (1), keeping Channels (2)\n    dim = ___\n\nmean = x.mean(dim, keepdim=True)",
              "solution": "(0, 1)",
              "hints": [
                "Pass a tuple of dimensions to reduce over."
              ]
            }
          ]
        }
      ]
    }, {
      "id": "course_llm_tokenization",
      "title": "LLM Tokenization: From Scratch",
      "thumbnail": "assets/tokenization-thumbnail.jpg",
      "description": "Let's build the GPT Tokenizer. Master the fundamental 'atom' of Large Language Models: the Token. Build a Byte Pair Encoding (BPE) tokenizer from scratch, understand Unicode and UTF-8, and debug common tokenization issues like the 'SolidGoldMagikarp' bug.",
      "sequence_order": 7,
      "chapters": [
        {
          "id": "tokenization_ch1",
          "title": "The Fundamentals: Unicode & UTF-8",
          "video_id": "zduSFxRajkE",
          "description": "We explore why LLMs can't just read raw text. We dive into the hierarchy of Python strings, Unicode Code Points, and UTF-8 Byte encodings to prepare the data for the BPE algorithm. ",
          "start": 0,
          "end": 1430,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Strings as sequences of Unicode Code Points",
            "Translating Code Points to UTF-8 Bytes",
            "Why raw byte sequences are inefficient for LLMs"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Convert a string to a list of its Unicode Code Points.",
              "template": "text = \"Hi \"\n# Get the integer representation of each character\ncode_points = [___(x) for x in text]",
              "solution": "ord",
              "hints": [
                "The `ord()` function returns the integer representing the Unicode character."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Convert a string to raw bytes using UTF-8 encoding.",
              "template": "text = \"Hello World\"\n# Encode into bytes\nbyte_data = text.encode(\"___\")\n# Convert bytes object to list of integers\nbyte_list = list(byte_data)",
              "solution": "utf-8",
              "hints": [
                "This is the standard variable-length encoding for the web."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why don't we just feed raw UTF-8 bytes directly into the Transformer?",
              "options": [
                "The sequence length would be too long, making the context window inefficient.",
                "Computers cannot process bytes.",
                "UTF-8 is proprietary."
              ],
              "solution": "The sequence length would be too long, making the context window inefficient.",
              "hints": [
                "Think about how many bytes it takes to represent a single emoji or complex character vs a single token."
              ]
            }
          ]
        },
        {
          "id": "tokenization_ch2",
          "title": "Byte Pair Encoding (BPE): Training",
          "video_id": "zduSFxRajkE",
          "description": "We implement the core logic of the BPE algorithm. We learn how to iteratively count adjacent pairs of bytes, identify the most frequent pair, and merge them to create new tokens, compressing the sequence.",
          "start": 1430,
          "end": 2567,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Counting pair frequencies in a sequence",
            "Merging the most frequent pair",
            "Managing vocabulary growth"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the function to count pair frequencies.",
              "template": "def get_stats(ids):\n    counts = {}\n    # Iterate through the list to find consecutive pairs\n    for pair in zip(ids, ids[1:]):\n        counts[pair] = counts.get(pair, 0) + ___\n    return counts",
              "solution": "1",
              "hints": [
                "Increment the count for the found pair."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Arrange the steps of the BPE training loop.",
              "solution": "stats = get_stats(ids)\npair = max(stats, key=stats.get)\nidx = 256 + i\nids = merge(ids, pair, idx)\nmerges[pair] = idx",
              "lines": [
                "ids = merge(ids, pair, idx)",
                "merges[pair] = idx",
                "stats = get_stats(ids)",
                "idx = 256 + i",
                "pair = max(stats, key=stats.get)"
              ],
              "hints": [
                "First calculate stats, find the max, define the new token ID, perform the merge, then save the record."
              ]
            }
          ]
        },
        {
          "id": "tokenization_ch3",
          "title": "Encoding & Decoding",
          "video_id": "zduSFxRajkE",
          "description": "We build the `encode` function to apply our learned merges to new text and the `decode` function to translate tokens back into strings, handling invalid UTF-8 sequences gracefully.",
          "start": 2567,
          "end": 3456,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Applying merges in the correct order (Encode)",
            "Mapping tokens back to bytes (Decode)",
            "Handling `errors='replace'` for invalid byte sequences"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Handle invalid byte sequences during decoding to avoid crashes.",
              "template": "def decode(ids):\n    # ... (byte concatenation logic)\n    # Decode bytes to string, replacing errors\n    text = tokens.decode(\"utf-8\", errors=\"___\")\n    return text",
              "solution": "replace",
              "hints": [
                "This uses the Unicode replacement character () for invalid bytes."
              ]
            },
            {
              "type": "code",
              "instruction": "In the encode function, we need to find the next mergeable pair with the lowest index (earliest merge).",
              "template": "while len(ids) >= 2:\n    stats = get_stats(ids)\n    # Find the pair in stats that exists in 'merges' with the smallest value\n    pair = min(stats, key=lambda p: merges.get(p, float(\"___\")))\n    if pair not in merges:\n        break",
              "solution": "inf",
              "hints": [
                "Use infinity as the default value to ignore pairs not present in our merge rules."
              ]
            }
          ]
        },
        {
          "id": "tokenization_ch4",
          "title": "Regex & GPT-4 Rules",
          "video_id": "zduSFxRajkE",
          "description": "We examine why GPT-2 and GPT-4 use complex Regex patterns to pre-split text. This prevents merging across different categories (e.g., merging punctuation with letters) and improves efficiency for code (Python whitespace). ",
          "start": 3456,
          "end": 5128,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "The purpose of pre-tokenization regex splitting",
            "Handling special tokens (e.g., <|endoftext|>)",
            "Differences between GPT-2 and GPT-4 whitespace handling"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What is the primary benefit of using a regex pattern to split text before BPE?",
              "options": [
                "It enforces that merges never cross category boundaries (e.g., letters won't merge with punctuation).",
                "It makes the code run faster on GPUs.",
                "It automatically translates text to English."
              ],
              "solution": "It enforces that merges never cross category boundaries (e.g., letters won't merge with punctuation).",
              "hints": [
                "Without this, a word like 'dog' and 'dog.' might become two completely unrelated unique tokens."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "GPT-4's regex handles case sensitivity differently than GPT-2. It uses the `?i` flag.",
              "template": "# GPT-2 pattern: 's|'t|'re ...\n# GPT-4 pattern: '(?___:[sdmt]|ll|ve|re)...",
              "solution": "i",
              "hints": [
                "This regex flag stands for case-insensitive."
              ]
            }
          ]
        },
        {
          "id": "tokenization_ch5",
          "title": "Libraries: Tiktoken & SentencePiece",
          "video_id": "zduSFxRajkE",
          "description": "We review the industry-standard libraries. `tiktoken` (OpenAI) is fast but inference-only. `sentencepiece` (Google/Llama) handles training and uses a different strategy involving unicode code points and byte fallback.",
          "start": 5128,
          "end": 6207,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Role of `tiktoken` in OpenAI models",
            "SentencePiece's 'byte fallback' mechanism",
            "Code points vs Byte-level BPE"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "How does `sentencepiece` (used in Llama) handle rare characters that aren't in the vocabulary?",
              "options": [
                "It falls back to UTF-8 bytes to represent them.",
                "It maps them all to a single <UNK> token.",
                "It crashes."
              ],
              "solution": "It falls back to UTF-8 bytes to represent them.",
              "hints": [
                "This ensures the model can process any string without producing 'unknown' tokens."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "SentencePiece introduces a dummy prefix to words. It replaces spaces with an underscore-like character.",
              "template": "# SentencePiece treats ' world' differently than 'world'\n# It uses the character: U+2581 (Lower One Eighth Block)\n# Often visualized as: ___",
              "solution": "_",
              "hints": [
                "It looks like an underscore."
              ]
            }
          ]
        },
        {
          "id": "tokenization_ch6",
          "title": "Vocab Size & Quirks",
          "video_id": "zduSFxRajkE",
          "description": "We discuss the trade-offs of vocabulary size, how to expand vocabularies for fine-tuning, and investigate the 'SolidGoldMagikarp' bug caused by under-trained tokens.",
          "start": 6207,
          "end": 8014,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Trade-offs: Computation vs Sequence Length vs Under-training",
            "Resizing Embedding Layers",
            "The 'SolidGoldMagikarp' phenomenon (Untrained tokens)"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why did the 'SolidGoldMagikarp' token cause GPT-3 to hallucinate or glitch?",
              "options": [
                "The token existed in the tokenizer vocab but appeared zero times in the training data, leaving its embedding vector un-updated (random noise).",
                "It was a secret trigger phrase programmed by OpenAI.",
                "It was a Pokemon copyright issue."
              ],
              "solution": "The token existed in the tokenizer vocab but appeared zero times in the training data, leaving its embedding vector un-updated (random noise).",
              "hints": [
                "Think about what happens to a vector that is initialized randomly and never receives a gradient update."
              ]
            },
            {
              "type": "code",
              "instruction": "If you add 5 new special tokens to a pre-trained model, you must resize the embedding matrix.",
              "template": "# old_vocab_size = 50257\n# num_new_tokens = 5\nmodel.transformer.wte.weight.resize_(___ + num_new_tokens, embedding_dim)",
              "solution": "old_vocab_size",
              "hints": [
                "The new size is the sum of the old size and the new tokens."
              ]
            }
          ]
        }
      ]
    },
     {
      "id": "course_build_gpt_scratch",
      "title": "Build GPT From Scratch with PyTorch",
      "thumbnail": "assets/build-gpt-thumbnail.jpg",
      "description": "A comprehensive code-along course building a Generative Pre-trained Transformer (GPT) from the ground up, following the 'Attention Is All You Need' architecture.",
      "sequence_order": 8,
      "chapters": [
        {
          "id": "gpt_ch1_data",
          "title": "Data Prep & Tokenization",
          "video_id": "kCc8FmEb1nY",
          "description": "We start by analyzing the Tiny Shakespeare dataset, building a character-level tokenizer, and encoding our text into integers for the model.",
          "start": 0,
          "end": 867,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "code",
              "instruction": "Create the mapping dictionaries to convert characters to integers (stoi) and integers to characters (itos).",
              "template": "chars = sorted(list(set(text)))\n# Create mapping from character to integer\nstoi = { ch:i for i,ch in enumerate(chars) }\n# Create mapping from integer to character\nitos = { ___ }",
              "solution": "i:ch for i,ch in enumerate(chars)",
              "hints": [
                "Use a dictionary comprehension similar to stoi, but swap keys and values."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Tokenization is the process of translating a string of text into a sequence of ___.",
              "template": "encoder = lambda s: [stoi[c] for c in s]\n# Output is a list of ___",
              "solution": "integers",
              "hints": [
                "The model cannot read raw text; it needs numbers."
              ]
            }
          ]
        },
        {
          "id": "gpt_ch2_bigram",
          "title": "Bigram Baseline & Training Loop",
          "video_id": "kCc8FmEb1nY",
          "description": "We implement a data loader to generate batches of input/target chunks and build a simple Bigram Language Model to establish a baseline performance. ",
          "start": 867,
          "end": 2280,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the `get_batch` function to fetch random chunks of data.",
              "template": "def get_batch(split):\n    data = train_data if split == 'train' else val_data\n    # Generate random starting indices for the batch\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    # y is the targets, shifted by 1\n    y = torch.stack([data[___] for i in ix])\n    return x, y",
              "solution": "i+1:i+block_size+1",
              "hints": [
                "The targets 'y' should be the next character for every character in 'x'."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Arrange the standard PyTorch training loop steps.",
              "solution": "logits, loss = model(xb, yb)\noptimizer.zero_grad(set_to_none=True)\nloss.backward()\noptimizer.step()",
              "lines": [
                "loss.backward()",
                "optimizer.step()",
                "logits, loss = model(xb, yb)",
                "optimizer.zero_grad(set_to_none=True)"
              ],
              "hints": [
                "First compute the loss (forward pass), then clear gradients, then calculate gradients (backward), then update weights."
              ]
            }
          ]
        },
        {
          "id": "gpt_ch3_math_attention",
          "title": "The Math of Self-Attention",
          "video_id": "kCc8FmEb1nY",
          "description": "We derive the mathematical foundation of attention by exploring how to efficiently aggregate information from past tokens using matrix multiplication and masking.",
          "start": 2280,
          "end": 3720,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why do we use a lower triangular matrix (tril) for masking in the attention mechanism?",
              "questions": [
                {
                  "question": "Why do we use a lower triangular matrix (tril) for masking in the attention mechanism?",
                  "options": [
                    "To prevent the model from seeing future tokens (cheating).",
                    "To save memory during training.",
                    "To ensure the matrix is invertible."
                  ],
                  "answer": "To prevent the model from seeing future tokens (cheating)."
                }
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the weighted aggregation using matrix multiplication. `wei` is the weight matrix (affinities).",
              "template": "# x is (B, T, C), wei is (T, T)\n# We want to perform a weighted sum of past vectors\n# Result shape should be (B, T, C)\nxbow = wei @ ___",
              "solution": "x",
              "hints": [
                "We multiply the weights by the values (x)."
              ]
            }
          ]
        },
        {
          "id": "gpt_ch4_self_attention",
          "title": "Implementing Self-Attention",
          "video_id": "kCc8FmEb1nY",
          "description": "We implement the core 'Head' of self-attention using Keys, Queries, and Values, allowing tokens to effectively 'search' for relevant information from the past. ",
          "start": 3720,
          "end": 4751,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "In self-attention: \n- What I am looking for: ___\n- What I contain: Key\n- What I communicate: Value",
              "template": "query = self.query(x)\nkey = self.key(x)\nvalue = self.value(x)",
              "solution": "query",
              "hints": [
                "It starts with Q."
              ]
            },
            {
              "type": "code",
              "instruction": "Calculate the attention scores (affinities) between Queries and Keys.",
              "template": "# q is (B, T, head_size), k is (B, T, head_size)\n# We need to transpose k to match dimensions: (B, T, C) @ (B, C, T) -> (B, T, T)\nwei = q @ k.transpose(___, ___)",
              "solution": "-2, -1",
              "hints": [
                "Transpose the last two dimensions."
              ]
            }
          ]
        },
        {
          "id": "gpt_ch5_multi_head",
          "title": "Multi-Head Attention & FeedForward",
          "video_id": "kCc8FmEb1nY",
          "description": "We upgrade the single head to Multi-Head Attention to capture different types of relationships and add a FeedForward network for computation per token.",
          "start": 4751,
          "end": 5208,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "To stabilize gradients, we scale the attention scores by dividing by the square root of the ___ dimension.",
              "template": "wei = wei * start_factor\n# This is k.shape[-1]\nscale_factor = head_size**-0.5",
              "solution": "head",
              "hints": [
                "It's the size of the key/query vectors."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Construct the FeedForward module structure.",
              "solution": "self.net = nn.Sequential(\n    nn.Linear(n_embd, 4 * n_embd),\n    nn.ReLU(),\n    nn.Linear(4 * n_embd, n_embd),\n)",
              "lines": [
                "self.net = nn.Sequential(",
                "    nn.Linear(n_embd, 4 * n_embd),",
                "    nn.ReLU(),",
                "    nn.Linear(4 * n_embd, n_embd),",
                ")"
              ],
              "hints": [
                "It projects up by 4x, applies non-linearity, then projects back down."
              ]
            }
          ]
        },
        {
          "id": "gpt_ch6_transformer_block",
          "title": "Residuals & LayerNorm",
          "video_id": "kCc8FmEb1nY",
          "description": "We assemble the full Transformer Block by adding Residual Connections (Skip Connections) and Layer Normalization to enable deep network training. ",
          "start": 5208,
          "end": 5869,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What is the primary purpose of Residual (Skip) Connections?",
              "questions": [
                {
                  "question": "What is the primary purpose of Residual (Skip) Connections?",
                  "options": [
                    "To allow gradients to flow directly through the network during backpropagation, helping with optimization depth.",
                    "To skip the computation of expensive layers.",
                    "To increase the number of parameters."
                  ],
                  "answer": "To allow gradients to flow directly through the network during backpropagation, helping with optimization depth."
                }
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the Forward pass of a Block with Residual connections.",
              "template": "# x is input\n# self.sa is Self-Attention, self.ffwd is FeedForward\n# self.ln1, self.ln2 are LayerNorms\nx = x + self.sa(self.ln1(x))\nx = x + ___",
              "solution": "self.ffwd(self.ln2(x))",
              "hints": [
                "Apply LayerNorm 2, then FeedForward, then add to the residual stream."
              ]
            }
          ]
        },
        {
          "id": "gpt_ch7_scaling",
          "title": "Scaling & Conclusion",
          "video_id": "kCc8FmEb1nY",
          "description": "We finalize the model with Dropout for regularization, scale up the parameters to create a larger GPT, and discuss the training process. ",
          "start": 5869,
          "end": 6979,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "___ is a regularization technique that randomly zeros out some elements during training to prevent overfitting.",
              "template": "self.dropout = nn.___(dropout_prob)",
              "solution": "Dropout",
              "hints": [
                "It 'drops' neurons out."
              ]
            },
            {
              "type": "quiz",
              "instruction": "What is the difference between Pre-training (what we did) and Fine-tuning (like ChatGPT)?",
              "questions": [
                {
                  "question": "What is the difference between Pre-training (what we did) and Fine-tuning (like ChatGPT)?",
                  "options": [
                    "Pre-training teaches the model to predict the next token on massive data; Fine-tuning aligns it to be a helpful assistant.",
                    "Pre-training is for images; Fine-tuning is for text.",
                    "They are the same thing."
                  ],
                  "answer": "Pre-training teaches the model to predict the next token on massive data; Fine-tuning aligns it to be a helpful assistant."
                }
              ]
            }
          ]
        }
      ]
    }, {
      "id": "course_reproducing_gpt2",
      "title": "Reproducing GPT-2 (124M) from Scratch",
      "thumbnail": "assets/gpt2-repro-thumbnail.jpg",
      "description": "A comprehensive deep dive into recreating OpenAI's GPT-2 (124M) model. This course covers everything from model architecture and weight loading to advanced optimization techniques like Flash Attention, Distributed Data Parallel (DDP), and mixed precision training.",
      "sequence_order": 9,
      "chapters": [
        {
          "id": "gpt2_ch1_intro",
          "title": "Exploring GPT-2 & Weights",
          "video_id": "l8pRSuU81PU",
          "description": "We analyze the GPT-2 124M architecture, download the official weights using Hugging Face, and inspect the shapes of the parameters, including the positional embeddings. ",
          "start": 0,
          "end": 827,
          "xp_reward": 30,
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What are the dimensions of the embedding layer in the GPT-2 124M model?",
              "questions": [
                {
                  "question": "What are the dimensions of the embedding layer in the GPT-2 124M model?",
                  "options": [
                    "50257 x 768",
                    "50257 x 1024",
                    "30522 x 768",
                    "768 x 768"
                  ],
                  "answer": "50257 x 768"
                }
              ]
            },
            {
              "type": "code",
              "instruction": "Load the pretrained GPT-2 model using the Transformers library and access its state dictionary.",
              "template": "from transformers import GPT2LMHeadModel\n\nmodel = GPT2LMHeadModel.from_pretrained(\"___\")\nsd = model.state_dict()\n\nfor k, v in sd.items():\n    print(k, v.shape)",
              "solution": "gpt2",
              "hints": [
                "The model name string is simply 'gpt2'."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch2_architecture",
          "title": "Implementing the Architecture",
          "video_id": "l8pRSuU81PU",
          "description": "We define the PyTorch `nn.Module` skeleton for GPT-2, ensuring our naming convention matches Hugging Face's for easy weight loading. We set up the configuration dataclass.",
          "start": 827,
          "end": 1688,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Define the `GPTConfig` class with the standard 124M hyperparameters.",
              "template": "@dataclass\nclass GPTConfig:\n    block_size: int = 1024\n    vocab_size: int = 50257\n    n_layer: int = 12\n    n_head: int = 12\n    n_embd: int = ___",
              "solution": "768",
              "hints": [
                "The embedding dimension for the base model is 768."
              ]
            },
            {
              "type": "code",
              "instruction": "Create the `ModuleDict` structure for the transformer body.",
              "template": "self.transformer = nn.ModuleDict(dict(\n    wte = nn.Embedding(config.vocab_size, config.n_embd),\n    wpe = nn.Embedding(config.block_size, config.n_embd),\n    h = nn.ModuleList([___(config) for _ in range(config.n_layer)]),\n    ln_f = nn.LayerNorm(config.n_embd),\n))",
              "solution": "Block",
              "hints": [
                "You need to instantiate a 'Block' module for each layer."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch3_loading_forward",
          "title": "Loading Weights & Forward Pass",
          "video_id": "l8pRSuU81PU",
          "description": "We implement the logic to copy weights from the Hugging Face model to our custom implementation, handling transposition for Conv1D weights. We also write the forward pass and generation loop.",
          "start": 1688,
          "end": 2750,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Arrange the steps to perform text generation.",
              "solution": "logits, _ = model(idx)\nlast_logits = logits[:, -1, :]\nprobs = F.softmax(last_logits, dim=-1)\ntopk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\nix = torch.multinomial(topk_probs, 1)\nidx = torch.cat((idx, ix), dim=1)",
              "lines": [
                "idx = torch.cat((idx, ix), dim=1)",
                "probs = F.softmax(last_logits, dim=-1)",
                "last_logits = logits[:, -1, :]",
                "logits, _ = model(idx)",
                "ix = torch.multinomial(topk_probs, 1)",
                "topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)"
              ],
              "hints": [
                "Get logits -> Focus on last step -> Softmax -> TopK -> Sample -> Append."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why do we need to transpose some weights when copying from the Hugging Face model?",
              "questions": [
                {
                  "question": "Why do we need to transpose some weights when copying from the Hugging Face model?",
                  "options": [
                    "Because Hugging Face uses Conv1D layers (weights are [Cin, Cout]) while our Linear layers expect [Cout, Cin].",
                    "Because TensorFlow and PyTorch use different memory layouts.",
                    "Because GPT-2 was trained in reverse."
                  ],
                  "answer": "Because Hugging Face uses Conv1D layers (weights are [Cin, Cout]) while our Linear layers expect [Cout, Cin]."
                }
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch4_training_loop",
          "title": "Basic Training Loop",
          "video_id": "l8pRSuU81PU",
          "description": "We switch to training mode. We prepare the Tiny Shakespeare dataset, implement the standard Cross Entropy Loss, and overfit a single batch to verify the pipeline.",
          "start": 2750,
          "end": 3720,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the Cross Entropy Loss in the forward pass.",
              "template": "if targets is not None:\n    # Flatten the logits and targets for cross_entropy\n    loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(___))",
              "solution": "-1",
              "hints": [
                "Targets need to be flattened to a 1D tensor."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "At initialization, for a vocab size of ~50k, the expected loss should be roughly -ln(1/50257) which is approximately ___.",
              "template": "expected_loss = ___",
              "solution": "10.8",
              "hints": [
                "It's roughly 11."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch5_data_sharing",
          "title": "Data Loader & Weight Tying",
          "video_id": "l8pRSuU81PU",
          "description": "We build a simple `DataLoaderLite` to stream batches of text. We also implement 'Weight Tying', sharing the weights between the token embedding layer and the final output head. ",
          "start": 3720,
          "end": 4427,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement Weight Tying in the model constructor.",
              "template": "# Tie the weights of the embedding layer and the head\nself.transformer.wte.weight = self.lm_head.___",
              "solution": "weight",
              "hints": [
                "They should point to the exact same tensor object."
              ]
            },
            {
              "type": "quiz",
              "instruction": "What is the benefit of Weight Tying in GPT-2?",
              "questions": [
                {
                  "question": "What is the benefit of Weight Tying in GPT-2?",
                  "options": [
                    "It significantly reduces the parameter count and improves performance.",
                    "It prevents the gradients from exploding.",
                    "It allows the model to process images."
                  ],
                  "answer": "It significantly reduces the parameter count and improves performance."
                }
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch6_initialization",
          "title": "Initialization Strategies",
          "video_id": "l8pRSuU81PU",
          "description": "We implement the specific initialization rules from the GPT-2 paper, including a special scaling rule for residual layers (1/sqrt(N)).",
          "start": 4427,
          "end": 4938,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the special initialization scaling for residual layers.",
              "template": "if hasattr(module, 'NANOGPT_SCALE_INIT'):\n    # Scale by 1/sqrt(2 * n_layer)\n    module.weight.data *= (2 * config.n_layer) ** ___",
              "solution": "-0.5",
              "hints": [
                "The power of -0.5 is equivalent to 1 over the square root."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Standard weights are initialized with a normal distribution with a mean of 0 and a standard deviation of ___.",
              "template": "std = ___",
              "solution": "0.02",
              "hints": [
                "It's a small number, often cited in the GPT-2/BERT papers."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch7_speed_precision",
          "title": "Speed: Mixed Precision (TF32 & BF16)",
          "video_id": "l8pRSuU81PU",
          "description": "We start optimizing for speed. We enable TensorFloat-32 (TF32) on Ampere GPUs and implement BFloat16 mixed precision training using `torch.autocast`. ",
          "start": 4938,
          "end": 6495,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "code",
              "instruction": "Enable TF32 on the GPU.",
              "template": "torch.backends.cuda.matmul.allow_tf32 = ___\ntorch.backends.cudnn.allow_tf32 = ___",
              "solution": "True",
              "hints": [
                "Just set the flag to True."
              ]
            },
            {
              "type": "code",
              "instruction": "Wrap the forward pass and loss calculation in the autocast context manager.",
              "template": "with torch.autocast(device_type=\"cuda\", dtype=torch.___):\n    logits, loss = model(x, y)",
              "solution": "bfloat16",
              "hints": [
                "We prefer bfloat16 over float16 for stability on Ampere GPUs."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why is BFloat16 often preferred over Float16 for training LLMs?",
              "questions": [
                {
                  "question": "Why is BFloat16 often preferred over Float16 for training LLMs?",
                  "options": [
                    "It has the same exponent range as Float32, preventing underflow/overflow without needing gradient scaling.",
                    "It has more precision bits than Float32.",
                    "It is the only format supported by NVIDIA."
                  ],
                  "answer": "It has the same exponent range as Float32, preventing underflow/overflow without needing gradient scaling."
                }
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch8_speed_compile_flash",
          "title": "Speed: Compilation & Flash Attention",
          "video_id": "l8pRSuU81PU",
          "description": "We introduce `torch.compile` to fuse kernels and reduce Python overhead. We then inspect the benefits of Flash Attention for IO-aware exact attention computation. ",
          "start": 6495,
          "end": 7614,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "To compile the model for faster execution, we use the command `model = torch.___(model)`.",
              "solution": "compile",
              "hints": [
                "It's a top-level torch function introduced in PyTorch 2.0."
              ]
            },
            {
              "type": "code",
              "instruction": "Replace manual attention implementation with the efficient PyTorch function.",
              "template": "y = F.scaled_dot_product_attention(q, k, v, is_causal=___)",
              "solution": "True",
              "hints": [
                "For GPT, the attention must be causal (masked)."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch9_vocab_optimization",
          "title": "Speed: The Power of Nice Numbers",
          "video_id": "l8pRSuU81PU",
          "description": "A weird but effective optimization: increasing the vocabulary size from 50,257 to 50,304 to align with powers of 2, making GPU kernels more efficient.",
          "start": 7614,
          "end": 8095,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why does changing the vocab size from 50257 to 50304 speed up training?",
              "questions": [
                {
                  "question": "Why does changing the vocab size from 50257 to 50304 speed up training?",
                  "options": [
                    "50304 is divisible by large powers of 2 (like 128), which aligns better with GPU memory/compute tiles, avoiding inefficient boundary checks.",
                    "It reduces the number of parameters in the model.",
                    "It prevents the model from generating padding tokens."
                  ],
                  "answer": "50304 is divisible by large powers of 2 (like 128), which aligns better with GPU memory/compute tiles, avoiding inefficient boundary checks."
                }
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch10_hyperparams",
          "title": "Hyperparameters & Learning Rates",
          "video_id": "l8pRSuU81PU",
          "description": "We implement the learning rate scheduler (warmup + cosine decay) and add gradient clipping to stabilize training.",
          "start": 8095,
          "end": 8781,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the cosine decay learning rate logic.",
              "template": "decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\ncoeff = 0.5 * (1.0 + math.cos(math.pi * ___))\nlr = min_lr + coeff * (max_lr - min_lr)",
              "solution": "decay_ratio",
              "hints": [
                "The cosine function takes an argument based on how far along the decay we are."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "To prevent exploding gradients, we use `torch.nn.utils.___` before the optimizer step.",
              "template": "norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)",
              "solution": "clip_grad_norm_",
              "hints": [
                "It limits the norm of the gradients."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch11_grad_accumulation",
          "title": "Gradient Accumulation",
          "video_id": "l8pRSuU81PU",
          "description": "We simulate a large batch size (e.g., 0.5M tokens) on limited hardware by accumulating gradients over multiple micro-steps before updating the weights.",
          "start": 8781,
          "end": 10012,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Construct the training loop with gradient accumulation.",
              "solution": "for micro_step in range(grad_accum_steps):\n    logits, loss = model(x, y)\n    loss = loss / grad_accum_steps\n    loss.backward()\noptimizer.step()\noptimizer.zero_grad()",
              "lines": [
                "optimizer.step()",
                "loss.backward()",
                "loss = loss / grad_accum_steps",
                "logits, loss = model(x, y)",
                "for micro_step in range(grad_accum_steps):",
                "optimizer.zero_grad()"
              ],
              "hints": [
                "The inner loop accumulates gradients. The optimizer step happens once after the loop."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why must we divide the loss by `grad_accum_steps` before calling backward?",
              "questions": [
                {
                  "question": "Why must we divide the loss by `grad_accum_steps` before calling backward?",
                  "options": [
                    "To ensure the accumulated gradient averages out correctly, mimicking the mean loss of a single large batch.",
                    "To prevent memory leaks.",
                    "To speed up the backward pass."
                  ],
                  "answer": "To ensure the accumulated gradient averages out correctly, mimicking the mean loss of a single large batch."
                }
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch12_ddp",
          "title": "Distributed Data Parallel (DDP)",
          "video_id": "l8pRSuU81PU",
          "description": "We scale up to multiple GPUs using DDP. We handle process ranks, data sharding, and gradient synchronization.",
          "start": 10012,
          "end": 11421,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "code",
              "instruction": "Initialize the process group for DDP.",
              "template": "from torch.distributed import init_process_group\ninit_process_group(backend=\"___\")",
              "solution": "nccl",
              "hints": [
                "The standard backend for NVIDIA GPUs starts with 'n'."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "In DDP, each process needs to know its global `rank`, local `local_rank`, and the total number of processes called `___`.",
              "solution": "world_size",
              "hints": [
                "It sounds like the size of the whole world."
              ]
            },
            {
              "type": "code",
              "instruction": "Wrap the model with DistributedDataParallel.",
              "template": "model = DDP(model, device_ids=[___])",
              "solution": "ddp_local_rank",
              "hints": [
                "You pass the ID of the specific GPU this process is using."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch13_datasets",
          "title": "FineWeb & Data Processing",
          "video_id": "l8pRSuU81PU",
          "description": "We switch to a real dataset: FineWeb-Edu. We discuss downloading, tokenizing, and sharding the data into numpy files for efficient streaming.",
          "start": 11421,
          "end": 12190,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What is the FineWeb-Edu dataset?",
              "questions": [
                {
                  "question": "What is the FineWeb-Edu dataset?",
                  "options": [
                    "A high-quality subset of Common Crawl filtered for educational value.",
                    "A collection of Shakespeare's works.",
                    "A dataset of Wikipedia articles only."
                  ],
                  "answer": "A high-quality subset of Common Crawl filtered for educational value."
                }
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch14_validation",
          "title": "Validation & HellaSwag Eval",
          "video_id": "l8pRSuU81PU",
          "description": "We implement a rigorous evaluation loop. We check validation loss and implement the HellaSwag benchmark logic to track model intelligence during training.",
          "start": 12190,
          "end": 13385,
          "xp_reward": 100,
          "tasks": [
            {
              "type": "code",
              "instruction": "In the HellaSwag evaluation, we pick the completion with the ___ average loss per token.",
              "template": "pred = losses.argmin()",
              "solution": "lowest",
              "hints": [
                "Lower loss means higher probability."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "When evaluating distributedly, we must gather results from all GPUs. We use `dist.___` to sum up the correct predictions across all ranks.",
              "solution": "all_reduce",
              "hints": [
                "It reduces (aggregates) data across all processes."
              ]
            }
          ]
        },
        {
          "id": "gpt2_ch15_results",
          "title": "Results & Conclusion",
          "video_id": "l8pRSuU81PU",
          "description": "We analyze the final training run, comparing our loss curves to OpenAI's GPT-2 and GPT-3 baselines. We discuss potential improvements and the llm.c C/CUDA implementation.",
          "start": 13385,
          "end": 14485,
          "xp_reward": 50,
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Did the 124M model trained on FineWeb-Edu for 10B tokens beat the original GPT-2 124M model on HellaSwag?",
              "questions": [
                {
                  "question": "Did the 124M model trained on FineWeb-Edu for 10B tokens beat the original GPT-2 124M model on HellaSwag?",
                  "options": [
                    "Yes, it surpassed the original GPT-2 baseline significantly.",
                    "No, it failed to converge.",
                    "It was exactly the same."
                  ],
                  "answer": "Yes, it surpassed the original GPT-2 baseline significantly."
                }
              ]
            }
          ]
        }
      ]
    }
 
 


 
 

  ]
}