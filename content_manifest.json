{
  "version": 1,
  "courses": [
    {
      "id": "course_intro_to_ai",
      "title": "Introduction to Artificial Intelligence",
      "thumbnail": "assets/ai-intro-thumbnail.jpg",
      "description": "A fundamental overview of AI, distinguishing between Weak and Strong AI, and exploring the hierarchy of Machine Learning and Deep Learning.",
      "sequence_order": 1,
      "chapters": [
        {
          "id": "intro_ai_ch1",
          "title": "Defining AI and Its Capabilities",
          "video_id": "ad79nYk2keg",
          "description": "We define Artificial Intelligence by looking at a robot's ability to adapt, reason, and solve problems. We then categorize AI into Weak (Narrow) and Strong forms, and clarify the relationship between AI, Machine Learning, and Deep Learning.",
          "start": 0,
          "end": 327,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Core Capabilities: Generalized Learning, Reasoning, Problem Solving",
            "Distinction between Weak AI (AlphaGo, Alexa) and Strong AI (Ultron)",
            "The hierarchy: AI > Machine Learning > Deep Learning",
            "Future concepts: The Singularity and Cyborgs"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Reconstruct the logic flow of the robot's capabilities as demonstrated in the field experiment.",
              "solution": "robot.adapt_to_lighting() # Generalized Learning\npath = robot.choose_path() # Reasoning\nrobot.use_plank_to_cross() # Problem Solving",
              "lines": [
                "robot.use_plank_to_cross() # Problem Solving",
                "robot.adapt_to_lighting() # Generalized Learning",
                "path = robot.choose_path() # Reasoning"
              ],
              "hints": [
                "First, the robot had to handle environmental changes.",
                "Second, it had to make a choice between roads.",
                "Finally, it had to overcome a physical obstacle."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why is Alexa considered 'Weak AI' (Narrow AI) despite its many features?",
              "options": [
                "It operates based on pre-trained keywords and lacks self-awareness.",
                "It cannot connect to the internet.",
                "It controls physical robots."
              ],
              "solution": "It operates based on pre-trained keywords and lacks self-awareness.",
              "hints": [
                "Try asking it something it wasn't trained for, like traffic status without prior setup.",
                "Weak AI focuses on specific tasks."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Complete the definition of Deep Learning based on the video's description.",
              "template": "# Machine Learning uses algorithms to learn from data\n# Deep Learning is a subset inspired by the:\nmodel_inspiration = \"___ brain\"",
              "solution": "human",
              "hints": [
                "It mimics the biological organ in our heads.",
                "This approach helps better perceive patterns."
              ]
            },
            {
              "type": "quiz",
              "instruction": "What is the 'Point of Singularity' predicted by Ray Kurzweil?",
              "options": [
                "The year 2045, when robots become as smart as humans.",
                "The moment AI becomes dangerous.",
                "The point where we stop using smartphones."
              ],
              "solution": "The year 2045, when robots become as smart as humans.",
              "hints": [
                "It involves a specific year mentioned in the video.",
                "It relates to the parity between human and machine intelligence."
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course_neural_networks_intro",
      "title": "Neural Networks: The Structure",
      "thumbnail": "assets/neural-networks-intro-thumbnail.jpg",
      "description": "A deep dive into the mathematical structure of neural networks, exploring how neurons, layers, weights, and biases collaborate to recognize handwritten digits.",
      "sequence_order": 2,
      "chapters": [
        {
          "id": "neural_nets_ch1",
          "title": "The Architecture of Layers",
          "video_id": "aircAruvnKk",
          "description": "Introduction to the biological inspiration behind neural networks, defining neurons as containers for activation numbers and explaining the hierarchical layered structure used to solve complex problems like digit recognition.",
          "start": 0,
          "end": 518,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Definition of a neuron's 'activation'",
            "Input and Output layer dimensions for MNIST",
            "The concept of Hidden Layers",
            "Hierarchical feature abstraction (Edges -> Loops -> Digits)"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "In this specific neural network model, what does a single 'neuron' essentially hold?",
              "options": [
                "A number between 0 and 1 representing activation",
                "A biological electrical impulse",
                "A complex image file"
              ],
              "solution": "A number between 0 and 1 representing activation",
              "hints": [
                "Think of it as a container for a single value.",
                "It represents how 'lit up' the cell is."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Calculate the input size. The input images are 28x28 pixels.",
              "template": "grid_width = 28\ngrid_height = 28\n# Each pixel is one neuron in the first layer\ntotal_input_neurons = ___",
              "solution": "784",
              "hints": [
                "Multiply the width by the height."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Arrange the logic flow of how the network *should* hierarchically analyze an image of a number.",
              "solution": "Detect specific edges\nIdentify patterns (loops, lines)\nRecognize the full digit",
              "lines": [
                "Recognize the full digit",
                "Detect specific edges",
                "Identify patterns (loops, lines)"
              ],
              "hints": [
                "It starts with the smallest components.",
                "It ends with the final classification."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Complete the terminology for the layers between input and output.",
              "template": "input_layer = network[0]\noutput_layer = network[-1]\n# The layers in the middle are called:\nmiddle_layers = \"___ layers\"",
              "solution": "hidden",
              "hints": [
                "They are not directly seen as input or output.",
                "The video refers to them as '___ layers' because their function is initially a mystery."
              ]
            }
          ]
        },
        {
          "id": "neural_nets_ch2",
          "title": "Weights, Biases, and The Sigmoid",
          "video_id": "aircAruvnKk",
          "description": "Deconstructing the mechanism of a single neuron. This chapter covers how weights assign importance to input pixels, how biases act as activation thresholds, and how the sigmoid function normalizes the output.",
          "start": 518,
          "end": 806,
          "xp_reward": 75,
          "key_learning_outcomes": [
            "The role of Weights in pattern matching",
            "The Weighted Sum calculation",
            "The role of Bias in thresholding",
            "The Sigmoid 'squishification' function"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If a neuron wants to detect a specific pixel pattern, how does it set its weights?",
              "options": [
                "Positive weights for matching pixels, negative for surrounding pixels",
                "All weights set to zero",
                "Random weights for all pixels"
              ],
              "solution": "Positive weights for matching pixels, negative for surrounding pixels",
              "hints": [
                "Think about the edge detection example.",
                "Green pixels meant positive, red meant negative."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the mathematical formula for a single neuron's processing *before* the activation function. Compute the weighted sum plus bias.",
              "template": "def calculate_z(inputs, weights, bias):\n    # inputs: list of pixel values\n    # weights: list of connection strengths\n    # bias: single number threshold\n    weighted_sum = 0\n    for i in range(len(inputs)):\n        weighted_sum += ___\n    return weighted_sum + ___",
              "solution": "def calculate_z(inputs, weights, bias):\n    # inputs: list of pixel values\n    # weights: list of connection strengths\n    # bias: single number threshold\n    weighted_sum = 0\n    for i in range(len(inputs)):\n        weighted_sum += inputs[i] * weights[i]\n    return weighted_sum + bias",
              "hints": [
                "Multiply the input by its corresponding weight.",
                "Don't forget to add the bias at the end."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Define the purpose of the Bias.",
              "template": "# The bias indicates how high the weighted sum needs to be\n# before the neuron becomes meaningfully ___",
              "solution": "active",
              "hints": [
                "It's about whether the neuron lights up or not."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "The output of the neuron is compressed into a 0-1 range using this function.",
              "template": "import math\n\ndef activation_function(x):\n    # This is the ___ function\n    return 1 / (1 + math.exp(-x))",
              "solution": "sigmoid",
              "hints": [
                "Also known as the logistic curve.",
                "Starts with 's'."
              ]
            }
          ]
        },
        {
          "id": "neural_nets_ch3",
          "title": "Matrix Notation & Modern Activations",
          "video_id": "aircAruvnKk",
          "description": "Transitioning to Linear Algebra notation for efficiency. This chapter explains how to represent layers as vectors and weights as matrices, and concludes with a discussion on ReLU vs Sigmoid.",
          "start": 806,
          "end": 1119,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Vector representation of activations",
            "Matrix-Vector multiplication for layers",
            "Compact mathematical notation sigma(Wa + b)",
            "ReLU (Rectified Linear Unit) definition"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Construct the clean linear algebra expression for the activation of the next layer.",
              "solution": "weighted_sum = np.dot(weights_matrix, activation_vector)\nz = weighted_sum + bias_vector\nnext_activations = sigmoid(z)",
              "lines": [
                "next_activations = sigmoid(z)",
                "weighted_sum = np.dot(weights_matrix, activation_vector)",
                "z = weighted_sum + bias_vector"
              ],
              "hints": [
                "Matrix multiplication happens first.",
                "Add the bias vector second.",
                "Apply the function last."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "In the matrix notation, what does 'W' represent?",
              "template": "# a(L) = sigmoid( W * a(L-1) + b )\n# W is the matrix containing all ___ connecting the two layers",
              "solution": "weights",
              "hints": [
                "These are the connection strengths."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why do modern networks often use ReLU instead of Sigmoid?",
              "options": [
                "ReLU is easier to train for deep networks",
                "ReLU outputs numbers between 0 and 1 only",
                "ReLU mimics the biology perfectly"
              ],
              "solution": "ReLU is easier to train for deep networks",
              "hints": [
                "Lisha Li mentions this in the interview.",
                "Sigmoid was 'old school'."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the ReLU function described in the interview.",
              "template": "def relu(x):\n    # Return x if x is positive, else 0\n    return ___",
              "solution": "def relu(x):\n    # Return x if x is positive, else 0\n    return max(0, x)",
              "hints": [
                "Use the max function.",
                "Compare x against 0."
              ]
            }
          ]
        }
      ]
    }, 
    {
      "id": "course_micrograd",
      "title": "Building Micrograd: Backpropagation from Scratch",
      "thumbnail": "assets/micrograd-thumbnail.jpg",
      "description": "Master the fundamentals of neural networks by building 'micrograd', a tiny Autograd engine, from scratch in Python.",
      "sequence_order": 3,
      "chapters": [
        {
          "id": "micrograd_ch1",
          "title": "The Intuition of Derivatives",
          "video_id": "VMj-3S1tku0",
          "description": "We start by defining the derivative conceptually as the 'rise over run' sensitivity of a function to its inputs. We implement a simple numerical estimation of the derivative for scalar functions. ",
          "start": 0,
          "end": 1149,
          "xp_reward": 30,
          "key_learning_outcomes": [
            "Definition of Derivative (Limit as h->0)",
            "Numerical estimation of slope",
            "Understanding function sensitivity"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the formula for the numerical approximation of a derivative.",
              "template": "def get_derivative(f, x, h=0.0001):\n    # Calculate rise over run\n    return (f(x + h) - ___) / ___",
              "solution": "def get_derivative(f, x, h=0.0001):\n    # Calculate rise over run\n    return (f(x + h) - f(x)) / h",
              "hints": [
                "Subtract the function value at x from the value at x+h.",
                "Divide by the step size h."
              ]
            },
            {
              "type": "quiz",
              "instruction": "If a function f(x) has a derivative of -3.0 at x=2.0, what does this imply?",
              "options": [
                "Increasing x slightly will decrease the output.",
                "Increasing x slightly will increase the output.",
                "The function is flat at x=2.0."
              ],
              "solution": "Increasing x slightly will decrease the output.",
              "hints": [
                "A negative slope means the function goes down as you go right."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch2",
          "title": "The Value Object & Visualization",
          "video_id": "VMj-3S1tku0",
          "description": "We define the core `Value` class to wrap scalar numbers, allowing us to track the history of operations for the computation graph. We implement `__add__` and `__mul__` to overload Python operators.",
          "start": 1149,
          "end": 1930,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Creating a Wrapper Class for scalars",
            "Operator Overloading (__add__, __mul__)",
            "Building the computation graph structure (children, ops)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Complete the Value class initialization to track graph connectivity.",
              "template": "class Value:\n    def __init__(self, data, _children=(), _op=''):\n        self.data = data\n        self.grad = 0.0\n        # Store the previous nodes to build the graph\n        self._prev = set(___)\n        self._op = _op",
              "solution": "_children",
              "hints": [
                "We need to convert the tuple of children into a set for the previous nodes."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the addition operator overloading.",
              "template": "def __add__(self, other):\n    # Create a new Value that is the sum of self and other\n    out = Value(self.data + other.data, (self, other), '+')\n    return out",
              "solution": "def __add__(self, other):\n    out = Value(self.data + other.data, (self, other), '+')\n    return out"
            }
          ]
        },
        {
          "id": "micrograd_ch3",
          "title": "Manual Backpropagation: The Basics",
          "video_id": "VMj-3S1tku0",
          "description": "We begin manually calculating derivatives for a simple expression graph. We discover how addition nodes 'route' gradients and multiplication nodes 'switch' gradients based on input values.",
          "start": 1930,
          "end": 2634,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Local Derivatives for Addition and Multiplication",
            "Routing vs Switching Gradients",
            "Understanding `grad` accumulation"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "In the expression `d = a + b`, if `dL/dd = 2.0`, what is `dL/da`?",
              "options": [
                "2.0 (The addition node distributes the gradient equally)",
                "1.0 (It divides the gradient)",
                "0.0"
              ],
              "solution": "2.0 (The addition node distributes the gradient equally)",
              "hints": [
                "The local derivative of addition is 1.0.",
                "Multiply global gradient by local derivative."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "For `d = a * b`, the gradient with respect to `a` depends on `b`.",
              "template": "# d = a * b\n# grad_a = grad_d * local_derivative\n# local_derivative of (a*b) with respect to a is ___\ngrad_a = grad_d * b.data",
              "solution": "b.data",
              "hints": [
                "Differentiation of ax with respect to x is a."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch4",
          "title": "The Chain Rule & Optimization",
          "video_id": "VMj-3S1tku0",
          "description": "We formalize the backpropagation logic using the Chain Rule from calculus, multiplying local derivatives by global gradients. We then perform a single manual optimization step to reduce the output.",
          "start": 2634,
          "end": 3172,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "The Chain Rule Formula",
            "Recursive application of gradients",
            "Nudging inputs to minimize/maximize output"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Order the logic for the Chain Rule as explained in the video.",
              "solution": "Find the derivative of the output w.r.t the current node\nMultiply it by the local derivative of the current node w.r.t input\nResult is the derivative of the output w.r.t the input",
              "lines": [
                "Multiply it by the local derivative of the current node w.r.t input",
                "Find the derivative of the output w.r.t the current node",
                "Result is the derivative of the output w.r.t the input"
              ],
              "hints": [
                "Start with the gradient coming from 'above' (the output)."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "To minimize the output `L`, we should adjust input `a` in the direction ___ to the gradient.",
              "template": "# Gradient Descent Step\n# a.data += step_size * (___ * a.grad)",
              "solution": "-1.0",
              "hints": [
                "The gradient points in the direction of increase.",
                "We want to go the opposite way."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch5",
          "title": "Backpropagating a Neuron",
          "video_id": "VMj-3S1tku0",
          "description": "We build a single Neuron model and manually backpropagate gradients through the hyperbolic tangent activation function.",
          "start": 3172,
          "end": 4142,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Structure of a Neuron (Weights, Bias, Activation)",
            "Derivative of tanh (1 - t^2)",
            "Backpropagating through composite functions"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the derivative calculation for the Tanh activation function, assuming `t` is the Tanh output.",
              "template": "def tanh_backward(t, grad_output):\n    # d/dx tanh(x) = 1 - tanh(x)^2\n    local_derivative = 1 - (t ** ___)\n    return grad_output * local_derivative",
              "solution": "2",
              "hints": [
                "It is one minus the square of the output."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why was the gradient for `w2` zero in the example shown?",
              "options": [
                "Because the input `x2` was zero, killing the gradient flow during multiplication.",
                "Because the weight was initialized to zero.",
                "Because tanh squashed it to zero."
              ],
              "solution": "Because the input `x2` was zero, killing the gradient flow during multiplication.",
              "hints": [
                "In multiplication d(w*x)/dw = x. If x is 0, what is the derivative?"
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch6",
          "title": "Automating Gradients",
          "video_id": "VMj-3S1tku0",
          "description": "We remove the manual work by implementing `_backward` closures for each operation and using Topological Sort to call them in the correct order automatically.",
          "start": 4142,
          "end": 4948,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Closures for backward passes",
            "Topological Sort for graph traversal",
            "The `backward()` method"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Arrange the steps for the automatic backward pass function.",
              "solution": "topo = build_topological_sort(self)\nself.grad = 1.0\nfor node in reversed(topo):\n    node._backward()",
              "lines": [
                "self.grad = 1.0",
                "for node in reversed(topo):\n    node._backward()",
                "topo = build_topological_sort(self)"
              ],
              "hints": [
                "We need the graph order first.",
                "We must initialize the gradient of the root node before propagating.",
                "We traverse in reverse topological order."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Define the backward closure for addition inside `__add__`.",
              "template": "def _backward():\n    self.grad += 1.0 * out.grad\n    other.grad += ___ * out.grad",
              "solution": "1.0",
              "hints": [
                "Addition distributes the gradient equally to both parents."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch7",
          "title": "Refining the Engine: Bugs & Powers",
          "video_id": "VMj-3S1tku0",
          "description": "We identify and fix a critical bug where gradients were being overwritten instead of accumulated. We then implement subtraction, division, and power operations to handle complex expressions.",
          "start": 4948,
          "end": 5971,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "The Gradient Accumulation Bug (+= vs =)",
            "Implementing Power Rule (x^k)",
            "Implementing Division as x * y^-1"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What happens if a variable is used multiple times in a graph (e.g., `b = a + a`) and we use `=` instead of `+=` for gradients?",
              "options": [
                "The gradient is incorrect because it only keeps the last branch's contribution.",
                "The gradient causes an infinite loop.",
                "Nothing, it works fine."
              ],
              "solution": "The gradient is incorrect because it only keeps the last branch's contribution.",
              "hints": [
                "Gradients from different paths must sum up (multivariate chain rule)."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the backward pass for the Power operation (x^k).",
              "template": "def _backward():\n    # d/dx (x^k) = k * x^(k-1)\n    self.grad += (other * self.data ** (other - 1)) * ___",
              "solution": "out.grad",
              "hints": [
                "Don't forget to multiply by the incoming global gradient from the output."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch8",
          "title": "PyTorch & Neural Network Modules",
          "video_id": "VMj-3S1tku0",
          "description": "We compare our engine to PyTorch's API and build higher-level classes: `Neuron`, `Layer`, and `MLP` (Multi-Layer Perceptron) to mimic deep learning libraries.",
          "start": 5971,
          "end": 6664,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "PyTorch Tensor API alignment",
            "Defining a Neuron class",
            "Defining an MLP (Multi-Layer Perceptron) class"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement the forward pass for a single Neuron.",
              "template": "def __call__(self, x):\n    # w * x + b\n    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n    out = act.tanh()\n    return ___",
              "solution": "out",
              "hints": [
                "Simply return the activated output."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "An MLP is a sequence of Layers.",
              "template": "class MLP(Module):\n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(___)\n        return x",
              "solution": "x",
              "hints": [
                "We pass the output of one layer as input to the next."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch9",
          "title": "Loss & Parameters",
          "video_id": "VMj-3S1tku0",
          "description": "We define a Mean Squared Error (MSE) loss function to measure performance and implement a method to recursively collect all parameters (weights and biases) from the network.",
          "start": 6664,
          "end": 7272,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Mean Squared Error (MSE) Loss formula",
            "Recursively collecting parameters",
            "Purpose of Loss functions"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the MSE loss for a single prediction and target.",
              "template": "diff = prediction - target\nloss = diff ** ___\n# In a real batch, we would average this",
              "solution": "2",
              "hints": [
                "MSE stands for Mean SQUARED Error."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Collect parameters from all neurons in a layer.",
              "template": "class Layer(Module):\n    def parameters(self):\n        return [p for neuron in self.neurons for p in neuron.___()]",
              "solution": "parameters",
              "hints": [
                "Call the parameters method of the individual neuron."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch10",
          "title": "The Training Loop",
          "video_id": "VMj-3S1tku0",
          "description": "We implement the full Gradient Descent loop: Forward pass, Zero Gradients, Backward pass, and Update. We debug a common issue where gradients accumulate incorrectly across steps.",
          "start": 7272,
          "end": 8043,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Gradient Descent Steps (Forward, Backward, Update)",
            "The necessity of `zero_grad`",
            "Learning Rate tuning"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Order the steps of a single training iteration.",
              "solution": "loss = model(inputs) # Forward pass\nmodel.zero_grad()\nloss.backward()\nfor p in model.parameters():\n    p.data += -0.01 * p.grad",
              "lines": [
                "loss.backward()",
                "model.zero_grad()",
                "loss = model(inputs) # Forward pass",
                "for p in model.parameters():\n    p.data += -0.01 * p.grad"
              ],
              "hints": [
                "Calculate loss first.",
                "Clear old gradients before calculating new ones.",
                "Backpropagate.",
                "Update weights."
              ]
            },
            {
              "type": "quiz",
              "instruction": "Why did the network train too fast and then become unstable before adding `zero_grad()`?",
              "options": [
                "The gradients were accumulating every step, effectively increasing the step size uncontrollably.",
                "The learning rate was set to 100.0.",
                "The random initialization was lucky."
              ],
              "solution": "The gradients were accumulating every step, effectively increasing the step size uncontrollably.",
              "hints": [
                "Remember the `+=` bug fix? It applies across training steps too if not cleared."
              ]
            }
          ]
        },
        {
          "id": "micrograd_ch11",
          "title": "Conclusion & Real-World Application",
          "video_id": "VMj-3S1tku0",
          "description": "We wrap up by reviewing the full code structure, looking at a more complex binary classification demo, and diving into the actual PyTorch codebase to find the `tanh` implementation.",
          "start": 8043,
          "end": 8751,
          "xp_reward": 30,
          "key_learning_outcomes": [
            "Micrograd vs Production Libraries (PyTorch)",
            "Understanding Stride/Offset in Tensors (Briefly)",
            "Real-world complexity of autograd kernels"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "When looking at the real PyTorch code, why was the `tanh` implementation so hard to find?",
              "options": [
                "It is buried in complex dispatch files involving CPU/GPU kernels and optimizations.",
                "It doesn't exist; PyTorch uses magic.",
                "It was in the root folder."
              ],
              "solution": "It is buried in complex dispatch files involving CPU/GPU kernels and optimizations.",
              "hints": [
                "Production libraries prioritize efficiency and hardware support over readability."
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course_makemore_bigram",
      "title": "Building Makemore: The Bigram Language Model",
      "thumbnail": "assets/makemore-thumbnail.jpg",
      "description": "Build a character-level language model from scratch. Start with a probabilistic bigram model using frequency counts, then evolve it into a neural network using PyTorch, covering tensors, broadcasting, softmax, and gradient descent.",
      "sequence_order": 4,
      "chapters": [
        {
          "id": "makemore_ch1",
          "title": "Bigrams & Data Exploration",
          "video_id": "PaCmpygFfXo",
          "description": "We begin by exploring the `names.txt` dataset and understanding the core concept of a Bigram Language Model: predicting the next character based solely on the previous one. We implement a simple counting mechanism using Python dictionaries.",
          "start": 0,
          "end": 765,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Concept of Character-Level Language Models",
            "Iterating over strings to form Bigrams",
            "Using `zip` for sliding windows",
            "Counting frequencies with Python dictionaries"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Use `zip` to iterate over a string `w` and create bigrams (consecutive character pairs).",
              "template": "w = \"emma\"\n# Create pairs (e, m), (m, m), (m, a)\nfor ch1, ch2 in zip(w, ___):\n    print(ch1, ch2)",
              "solution": "w[1:]",
              "hints": [
                "You want to zip the string with a version of itself shifted by one index."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Count occurrences of bigrams in a dictionary `b`.",
              "template": "bigram = (ch1, ch2)\n# Get current count, default to 0 if not found, then add 1\nb[bigram] = b.get(bigram, ___) + 1",
              "solution": "0",
              "hints": [
                "The default value for a counter should be zero."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch2",
          "title": "Tensors & Visualizing Counts",
          "video_id": "PaCmpygFfXo",
          "description": "We migrate from Python dictionaries to PyTorch Tensors for efficiency. We build a 2D integer tensor to store counts and create mappings (`stoi` and `itos`) to convert between characters and integer indices. ",
          "start": 765,
          "end": 1442,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Creating PyTorch Tensors (`torch.zeros`)",
            "String-to-Integer (`stoi`) and Integer-to-String (`itos`) mappings",
            "Indexing into 2D Tensors"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Initialize a 27x27 tensor of integers to store the counts.",
              "template": "import torch\n# We need 27 characters (26 letters + 1 special token)\nN = torch.zeros((27, 27), dtype=torch.___)",
              "solution": "int32",
              "hints": [
                "We are storing counts, so we need an integer type.",
                "The video suggests int32."
              ]
            },
            {
              "type": "code",
              "instruction": "Create the `stoi` (string to integer) mapping for lowercase letters.",
              "template": "chars = sorted(list(set(''.join(words))))\n# Map characters to integers starting from 1 (reserving 0 for special token)\nstoi = {s:___ for i, s in enumerate(chars)}",
              "solution": "i+1",
              "hints": [
                "Ensure the index `i` is shifted by 1."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch3",
          "title": "Sampling & Generators",
          "video_id": "PaCmpygFfXo",
          "description": "We convert raw counts into probability distributions and use `torch.multinomial` to sample new characters. We also learn about `torch.Generator` to ensure our results are deterministic and reproducible.",
          "start": 1442,
          "end": 2177,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Converting counts to probabilities",
            "Using `torch.multinomial` for sampling",
            "Deterministic randomness with `torch.Generator`"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why do we use `torch.Generator` with a manual seed?",
              "options": [
                "To ensure the random sampling is reproducible every time we run the code.",
                "To make the code run faster.",
                "To automatically optimize the tensor operations."
              ],
              "solution": "To ensure the random sampling is reproducible every time we run the code.",
              "hints": [
                "It allows us to get the exact same 'random' numbers."
              ]
            },
            {
              "type": "code",
              "instruction": "Sample 1 index from a probability distribution `p`.",
              "template": "g = torch.Generator().manual_seed(2147483647)\n# p is a vector of probabilities\nix = torch.multinomial(p, num_samples=___, replacement=True, generator=g).item()",
              "solution": "1",
              "hints": [
                "We only want a single next character index."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch4",
          "title": "Broadcasting & Vectorization",
          "video_id": "PaCmpygFfXo",
          "description": "We optimize the normalization step using vectorization. This chapter dives deep into PyTorch's Broadcasting semantics, a powerful but dangerous feature that can introduce silent bugs if dimensions aren't managed correctly.",
          "start": 2177,
          "end": 3014,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Vectorized row-wise summation",
            "The `keepdim=True` argument",
            "PyTorch Broadcasting Rules (Align right, create dimension 1)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Calculate the sum of each row (dimension 1) while keeping the dimension to allow for broadcasting.",
              "template": "# P is a (27, 27) tensor\n# We want a (27, 1) vector of sums\nP_sum = P.sum(dim=1, keepdim=___)",
              "solution": "True",
              "hints": [
                "If we don't keep the dimension, it squeezes to (27,), which might broadcast incorrectly as a row vector."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Order the steps to correctly normalize the probability matrix P.",
              "solution": "P = N.float()\nP_sum = P.sum(1, keepdim=True)\nP = P / P_sum",
              "lines": [
                "P = P / P_sum",
                "P_sum = P.sum(1, keepdim=True)",
                "P = N.float()"
              ],
              "hints": [
                "Convert to float first.",
                "Calculate the sum.",
                "Divide."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch5",
          "title": "Maximum Likelihood & Loss",
          "video_id": "PaCmpygFfXo",
          "description": "We introduce the concept of Loss to evaluate the model's quality. We derive the Negative Log Likelihood (NLL) and discuss Model Smoothing to handle infinite loss caused by zero-probability events.",
          "start": 3014,
          "end": 3777,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Likelihood vs Log Likelihood",
            "Negative Log Likelihood (NLL) as a Loss Function",
            "Model Smoothing (Fake Counts)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Calculate the Negative Log Likelihood (NLL) loss.",
              "template": "# prob is the probability assigned to the correct character\nlog_prob = torch.log(prob)\nloss = -___",
              "solution": "log_prob",
              "hints": [
                "We want to minimize the negative of the log probability."
              ]
            },
            {
              "type": "quiz",
              "instruction": "What is the purpose of 'Model Smoothing' (adding counts to N)?",
              "options": [
                "To prevent zero probabilities, which cause infinite loss.",
                "To make the model train faster.",
                "To reduce the number of parameters."
              ],
              "solution": "To prevent zero probabilities, which cause infinite loss.",
              "hints": [
                "Log of zero is negative infinity."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch6",
          "title": "The Neural Network Approach",
          "video_id": "PaCmpygFfXo",
          "description": "We shift paradigms from counting to Neural Networks. We prepare the dataset for the NN using One-Hot Encoding and implement the first Linear Layer using Matrix Multiplication. ",
          "start": 3777,
          "end": 4726,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "One-Hot Encoding inputs",
            "Matrix Multiplication (@ operator)",
            "Initializing weights randomly"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "One-hot encode a tensor of integers `xs` and cast it to float.",
              "template": "import torch.nn.functional as F\n# xs contains integers. Encode to 27 classes.\nxenc = F.one_hot(xs, num_classes=27).___()",
              "solution": "float",
              "hints": [
                "Neural networks expect floating point inputs, but one_hot returns integers by default."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Perform the linear transformation (Matrix Multiplication).",
              "template": "# xenc is (5, 27), W is (27, 27)\nlogits = xenc ___ W",
              "solution": "@",
              "hints": [
                "Use the Python operator for matrix multiplication."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch7",
          "title": "Logits & Softmax",
          "video_id": "PaCmpygFfXo",
          "description": "We interpret the output of the linear layer as 'logits' (log-counts). We apply the Softmax function (exponentiation followed by normalization) to convert logits into valid probability distributions.",
          "start": 4726,
          "end": 5749,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Interpretation of Logits",
            "The Softmax Function (exp -> normalize)",
            "Numerical stability of probabilities"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Implement the Softmax function on the logits.",
              "solution": "counts = logits.exp()\nprobs = counts / counts.sum(1, keepdims=True)",
              "lines": [
                "probs = counts / counts.sum(1, keepdims=True)",
                "counts = logits.exp()"
              ],
              "hints": [
                "First, exponentiate the logits to get 'fake counts'.",
                "Then, normalize the counts to sum to 1."
              ]
            },
            {
              "type": "quiz",
              "instruction": "If the logits are negative numbers, what happens when we apply `.exp()`?",
              "options": [
                "They become positive numbers between 0 and 1.",
                "They become negative numbers.",
                "They become undefined."
              ],
              "solution": "They become positive numbers between 0 and 1.",
              "hints": [
                "e^x for x < 0 is a small positive number."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch8",
          "title": "Optimization: Gradient Descent",
          "video_id": "PaCmpygFfXo",
          "description": "We implement the full training loop. We calculate the vectorized loss, perform the backward pass (Backpropagation), and update the weights to minimize the loss. ",
          "start": 5749,
          "end": 6469,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Vectorized Loss Calculation",
            "The Backward Pass (`loss.backward()`)",
            "Gradient Descent Update (`data += -lr * grad`)"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Extract the probabilities assigned to the correct targets for the loss calculation.",
              "template": "# probs is (5, 27), ys is (5,)\n# We want to pick the probability for the correct label in each row\nloss_probs = probs[torch.arange(5), ___]",
              "solution": "ys",
              "hints": [
                "Use the target labels `ys` as the column indices."
              ]
            },
            {
              "type": "code",
              "instruction": "Perform the weight update step.",
              "template": "# W is the weight tensor\nlearning_rate = 0.1\nW.data += -learning_rate * ___",
              "solution": "W.grad",
              "hints": [
                "We move in the opposite direction of the gradient."
              ]
            }
          ]
        },
        {
          "id": "makemore_ch9",
          "title": "Regularization & Summary",
          "video_id": "PaCmpygFfXo",
          "description": "We discuss the connection between 'Model Smoothing' in the counting approach and 'Weight Regularization' in the neural network. We conclude by sampling from the trained neural network.",
          "start": 6469,
          "end": 7064,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Model Smoothing as Weight Decay",
            "Sampling from the Neural Network",
            "Equivalence of Counting and Single-Layer NN"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "How does forcing weights `W` towards zero act as regularization (smoothing)?",
              "options": [
                "Zero weights lead to zero logits, which result in a uniform probability distribution.",
                "Zero weights make the model output zeros.",
                "It prevents the model from calculating gradients."
              ],
              "solution": "Zero weights lead to zero logits, which result in a uniform probability distribution.",
              "hints": [
                "exp(0) = 1. If all logits are 0, all counts are 1."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Before the backward pass in the training loop, what must we do to the gradients?",
              "template": "# Reset gradients to zero\nW.grad = ___",
              "solution": "None",
              "hints": [
                "In PyTorch, we can set `.grad` to this special value to indicate no gradient."
              ]
            }
          ]
        }
      ]
    },
    {
      "id": "course_makemore_mlp",
      "title": "Building Makemore: The Multi-Layer Perceptron",
      "thumbnail": "assets/makemore-mlp-thumbnail.jpg",
      "description": "Upgrade your language model from a simple bigram to a Multi-Layer Perceptron (MLP) following the Bengio et al. 2003 paper. Master embeddings, tensor internals, and proper training methodology.",
      "sequence_order": 5,
      "chapters": [
        {
          "id": "makemore_mlp_ch1",
          "title": "Context, Dataset & Embeddings",
          "video_id": "TCH_1BHY58I",
          "description": "We explore the limitations of n-gram models and introduce the Neural Probabilistic Language Model (Bengio et al. 2003). We build a dataset with a sliding context window and implement the first layer of the network: the Embedding Lookup Table. ",
          "start": 0,
          "end": 1115,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "The curse of dimensionality in n-gram models",
            "Building a sliding window dataset (X, Y)",
            "Implementing character embeddings using matrix indexing"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why does the table-based n-gram approach fail as we increase the context length (e.g., looking back 10 characters)?",
              "options": [
                "The table size grows exponentially, resulting in sparse counts and overfitting.",
                "Computers cannot handle tables larger than 27x27.",
                "It becomes impossible to tokenize the characters."
              ],
              "solution": "The table size grows exponentially, resulting in sparse counts and overfitting.",
              "hints": [
                "Think about how many possible combinations of 10 characters exist (27^10)."
              ]
            },
            {
              "type": "code",
              "instruction": "Construct the input dataset `X` and labels `Y` for a block size of 3.",
              "template": "block_size = 3\nX, Y = [], []\ncontext = [0] * block_size\nfor ch in text:\n    ix = stoi[ch]\n    X.append(context)\n    Y.append(___)\n    context = context[1:] + [___]",
              "solution": "ix",
              "hints": [
                "Y contains the current character index.",
                "Update the context by appending the new index."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Implement the embedding lookup. `C` is the embedding matrix, `X` is the tensor of input indices.",
              "template": "# PyTorch allows indexing with tensors\n# If X is (32, 3) and C is (27, 2)\n# We want the output to be (32, 3, 2)\nemb = C[___]",
              "solution": "X",
              "hints": [
                "You can pass the index tensor directly into the embedding matrix."
              ]
            }
          ]
        },
        {
          "id": "makemore_mlp_ch2",
          "title": "Tensor Internals & The Hidden Layer",
          "video_id": "TCH_1BHY58I",
          "description": "We implement the hidden layer of the MLP. Crucially, we dive deep into PyTorch tensor internals (`storage` vs `view`) to efficiently flatten our input dimensions without copying memory. ",
          "start": 1115,
          "end": 1969,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Efficient reshaping with `.view()` vs `.cat()`",
            "PyTorch Tensor Internals: Storage vs View",
            "Implementing the hidden layer calculation ($tanh(XW+b)$)"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "What is the primary advantage of using `.view()` compared to `torch.cat()` when reshaping tensors?",
              "options": [
                "`.view()` does not copy memory; it just changes how the underlying storage is interpreted.",
                "`.view()` automatically calculates gradients.",
                "`.view()` sorts the data elements."
              ],
              "solution": "`.view()` does not copy memory; it just changes how the underlying storage is interpreted.",
              "hints": [
                "Think about efficiency and memory allocation."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Reshape the embedding tensor `emb` of shape (32, 3, 2) to (32, 6) to feed into the linear layer, using the most efficient method.",
              "solution": "# emb.shape is (32, 3, 2)\n# We want to flatten the last two dimensions\nflattened = emb.view(emb.shape[0], 6)",
              "lines": [
                "flattened = emb.view(emb.shape[0], 6)",
                "flattened = torch.cat(torch.unbind(emb, 1), 1)",
                "flattened = emb.storage()"
              ],
              "hints": [
                "Avoid creating new tensors if possible."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Calculate the hidden states `h`. Remember to apply the non-linearity.",
              "template": "# emb_view is the flattened input (N, inputs)\n# W1 and b1 are weights and bias\npre_activation = emb_view @ W1 + b1\nh = torch.___(pre_activation)",
              "solution": "tanh",
              "hints": [
                "The Bengio paper and our implementation use the hyperbolic tangent function."
              ]
            }
          ]
        },
        {
          "id": "makemore_mlp_ch3",
          "title": "Optimization & Training Loop",
          "video_id": "TCH_1BHY58I",
          "description": "We professionalize the training loop. We replace our manual loss calculation with `F.cross_entropy` for numerical stability, implement minibatch training for speed, and use a learning rate finder to tune hyperparameters.",
          "start": 1969,
          "end": 3200,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Advantages of `F.cross_entropy` (LogSumExp trick)",
            "Implementing Minibatches",
            "Finding a good learning rate using an exponent scan"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why is `F.cross_entropy(logits, targets)` preferred over manually calculating `softmax` then `nll_loss`?",
              "options": [
                "It uses the LogSumExp trick for numerical stability and efficient backward passes.",
                "It is the only way to calculate loss in PyTorch.",
                "It automatically tunes the learning rate."
              ],
              "solution": "It uses the LogSumExp trick for numerical stability and efficient backward passes.",
              "hints": [
                "Think about what happens if exponentials get very large (overflow)."
              ]
            },
            {
              "type": "code",
              "instruction": "Select a minibatch of indices `ix`.",
              "template": "batch_size = 32\n# X is the training data tensor\n# Generate 32 random indices between 0 and len(X)\nix = torch.randint(0, ___, (batch_size,))",
              "solution": "X.shape[0]",
              "hints": [
                "You need the upper bound of the random integer range."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Construct the list of learning rates to scan exponentially.",
              "template": "# Create 1000 exponents between -3 and 0\nlre = torch.linspace(-3, 0, 1000)\n# Calculate actual learning rates\nlrs = 10 ** ___",
              "solution": "lre",
              "hints": [
                "10 to the power of the exponent."
              ]
            }
          ]
        },
        {
          "id": "makemore_mlp_ch4",
          "title": "Methodology: Splits & Sampling",
          "video_id": "TCH_1BHY58I",
          "description": "We discuss proper machine learning methodology: splitting data into Train, Validation, and Test sets to detect overfitting. We scale up the network parameters and conclude by generating samples from our trained MLP.",
          "start": 3200,
          "end": 4539,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Train/Validation/Test Split methodology",
            "Detecting Overfitting vs Underfitting",
            "Sampling from the MLP",
            "Visualizing Embeddings"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If your training loss is very low but your validation loss is very high, what is likely happening?",
              "options": [
                "Overfitting: The model is memorizing the training data but not generalizing.",
                "Underfitting: The model is too simple to learn the pattern.",
                "The learning rate is too low."
              ],
              "solution": "Overfitting: The model is memorizing the training data but not generalizing.",
              "hints": [
                "The model performs great on data it has seen, but fails on new data."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "When sampling, we convert the network output logits into probabilities using this function.",
              "template": "# logits is the output of the final layer\nprobs = F.___(logits, dim=1)",
              "solution": "softmax",
              "hints": [
                "This function ensures the outputs sum to 1 and are positive."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Order the steps to sample a single character from the model.",
              "solution": "logits = model(context)\nprobs = F.softmax(logits, dim=1)\nix = torch.multinomial(probs, num_samples=1).item()\ncontext = context[1:] + [ix]",
              "lines": [
                "probs = F.softmax(logits, dim=1)",
                "context = context[1:] + [ix]",
                "ix = torch.multinomial(probs, num_samples=1).item()",
                "logits = model(context)"
              ],
              "hints": [
                "Forward pass -> Probability -> Sample Index -> Update Context."
              ]
            }
          ]
        }
      ]
    },{
      "id": "course_makemore_batchnorm",
      "title": "Makemore: Initialization & Batch Normalization",
      "thumbnail": "assets/makemore-batchnorm-thumbnail.jpg",
      "description": "Deep dive into the 'black magic' of training deep neural networks. Learn how to diagnose training issues, properly initialize weights (Kaiming Init), and implement Batch Normalization from scratch to stabilize training.",
      "sequence_order": 6,
      "chapters": [
        {
          "id": "makemore_bn_ch1",
          "title": "Diagnosing Initialization",
          "video_id": "P6sfmUTpUmc",
          "description": "We analyze the initial loss of the network and realize it is 'confidently wrong'.  We fix this by scaling down the output weights to ensure a uniform probability distribution at the start.",
          "start": 0,
          "end": 779,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Calculating expected initial loss (-log(1/vocab_size))",
            "The 'Hockey Stick' loss curve phenomenon",
            "Initializing output logits to be small/uniform"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If you have a vocabulary of 27 characters and initialize your network correctly, what should the initial loss roughly be?",
              "options": [
                "Approximately 3.3 (-log(1/27))",
                "Approximately 27.0",
                "Exactly 0.0"
              ],
              "solution": "Approximately 3.3 (-log(1/27))",
              "hints": [
                "It should be the negative log likelihood of a uniform distribution."
              ]
            },
            {
              "type": "code",
              "instruction": "Scale down the weights `W2` and biases `b2` of the final layer to ensure logits are close to zero at initialization.",
              "template": "# W2 is shape (n_hidden, vocab_size), b2 is (vocab_size)\nW2 = torch.randn((n_hidden, vocab_size)) * ___\nb2 = torch.randn(vocab_size) * ___",
              "solution": "W2 = torch.randn((n_hidden, vocab_size)) * 0.01\nb2 = torch.randn(vocab_size) * 0",
              "hints": [
                "Multiply weights by a small number (e.g., 0.01).",
                "Set biases to zero."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch2",
          "title": "Activations & The Vanishing Gradient",
          "video_id": "P6sfmUTpUmc",
          "description": "We visualize the hidden layer activations and discover they are saturated at -1 and 1. We explore how this causes the 'Vanishing Gradient' problem for Tanh units and discuss the concept of 'Dead Neurons' in ReLU networks.",
          "start": 779,
          "end": 1673,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Visualizing activation histograms",
            "Tanh derivative property (1 - t^2)",
            "The problem of saturated activations stopping backprop"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If a Tanh neuron's output is 1.0 or -1.0, what happens to the gradient flowing through it during backpropagation?",
              "options": [
                "It becomes zero (destroyed).",
                "It becomes 1 (passed through).",
                "It becomes infinite (exploded)."
              ],
              "solution": "It becomes zero (destroyed).",
              "hints": [
                "The derivative of tanh(x) is 1 - tanh(x)^2."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "Check for saturated neurons. We consider a neuron saturated if its absolute value is close to 1.",
              "template": "h_preact = emb @ W1 + b1\n# Create a boolean tensor where True indicates saturation\nsaturated = h_preact.abs() > ___\n# Check if any neuron is saturated for ALL examples (dead neuron)\ndead_neurons = saturated.all(dim=0).any()",
              "solution": "0.97",
              "hints": [
                "Pick a threshold close to 1, like 0.97 or 0.99."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch3",
          "title": "Kaiming Initialization",
          "video_id": "P6sfmUTpUmc",
          "description": "We implement a principled way to initialize weights to keep activation variance constant throughout the network, known as Kaiming (or He) Initialization.",
          "start": 1673,
          "end": 2440,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "The goal of preserving variance (std=1) across layers",
            "The Kaiming Init formula: gain / sqrt(fan_in)",
            "Gain values for Tanh vs ReLU"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Implement Kaiming Normal initialization for a Tanh layer.",
              "template": "fan_in = 30 # dimensionality of input\n# Gain for Tanh is usually 5/3\ngain = 5/3\n# Standard deviation should be gain / sqrt(fan_in)\nstd = gain / (fan_in ** ___)\nW1 = torch.randn((fan_in, 200)) * std",
              "solution": "0.5",
              "hints": [
                "Power of 0.5 is the square root."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Arrange the logic explaining why we scale weights by 1/sqrt(fan_in).",
              "solution": "Multiplying inputs by weights increases the variance of the output\nTo counteract this expansion, we must scale down the weights\nThe correct scale factor is 1 over the square root of the number of inputs",
              "lines": [
                "The correct scale factor is 1 over the square root of the number of inputs",
                "Multiplying inputs by weights increases the variance of the output",
                "To counteract this expansion, we must scale down the weights"
              ],
              "hints": [
                "Start with the problem (variance expansion)."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch4",
          "title": "Batch Normalization: Training",
          "video_id": "P6sfmUTpUmc",
          "description": "We introduce the 2015 innovation that stabilized deep networks: Batch Normalization. We implement the layer from scratch, normalizing inputs to be unit Gaussian and then scaling/shifting them.",
          "start": 2440,
          "end": 3240,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Calculating Mean and Variance of a batch",
            "Normalizing inputs: (x - mean) / sqrt(var + eps)",
            "Learnable Scale (Gamma) and Shift (Beta) parameters"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the mean and variance of the pre-activations `hpreact` across the batch dimension (dim 0).",
              "template": "# hpreact shape is (32, 200)\n# We want mean shape to be (1, 200) for broadcasting\nbn_mean = hpreact.mean(dim=0, keepdim=___)\nbn_var = hpreact.var(dim=0, keepdim=___)",
              "solution": "True",
              "hints": [
                "We need to keep the dimensions to allow for proper broadcasting later."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Order the operations inside the Batch Normalization forward pass.",
              "solution": "Calculate batch mean and variance\nNormalize inputs to unit variance (standardization)\nScale and shift using learned parameters (gamma, beta)",
              "lines": [
                "Scale and shift using learned parameters (gamma, beta)",
                "Calculate batch mean and variance",
                "Normalize inputs to unit variance (standardization)"
              ],
              "hints": [
                "You must know the stats before you can normalize."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch5",
          "title": "Batch Normalization: Inference",
          "video_id": "P6sfmUTpUmc",
          "description": "We solve the problem of how to use BatchNorm with single examples at inference time. We introduce running buffers (running_mean, running_var) and update them with momentum.",
          "start": 3240,
          "end": 3890,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Training vs Inference behavior of BatchNorm",
            "Running Mean/Var buffers",
            "Momentum updates for running stats"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why can't we just use the batch statistics during inference (test time)?",
              "options": [
                "We might be processing a single example, so variance would be undefined/zero.",
                "It is too computationally expensive.",
                "The paper says not to."
              ],
              "solution": "We might be processing a single example, so variance would be undefined/zero.",
              "hints": [
                "Statistics require a population. A single example has no mean/var relative to itself."
              ]
            },
            {
              "type": "code",
              "instruction": "Update the running mean using a small momentum (e.g., 0.001).",
              "template": "momentum = 0.001\n# Exponential moving average update\nrunning_mean = (1 - momentum) * running_mean + momentum * ___",
              "solution": "bn_mean",
              "hints": [
                "We mix the old running mean with the current batch mean."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch6",
          "title": "Productionizing: Modules & ResNet",
          "video_id": "P6sfmUTpUmc",
          "description": "We restructure our messy code into PyTorch-style classes (`nn.Module`). We also briefly look at ResNet code to see these same principles (BatchNorm, Conv, ReLU) applied in state-of-the-art architectures.",
          "start": 3890,
          "end": 5211,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Structure of PyTorch `nn.Module`",
            "Implementing `__init__` and `__call__`",
            "Structure of a ResNet block (Conv -> BN -> ReLU)"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Complete the initialization of the Linear layer class.",
              "template": "class Linear:\n    def __init__(self, fan_in, fan_out, bias=True):\n        self.weight = torch.randn((fan_in, fan_out)) / (fan_in**0.5)\n        self.bias = torch.zeros(fan_out) if ___ else None",
              "solution": "bias",
              "hints": [
                "Check the boolean argument provided to the constructor."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the Linear layer forward pass in `__call__`.",
              "template": "def __call__(self, x):\n    self.out = x @ self.weight\n    if self.bias is not None:\n        self.out += ___\n    return self.out",
              "solution": "self.bias",
              "hints": [
                "Add the bias if it exists."
              ]
            }
          ]
        },
        {
          "id": "makemore_bn_ch7",
          "title": "Diagnostic Visualizations",
          "video_id": "P6sfmUTpUmc",
          "description": "We create powerful visualization tools to inspect the health of our network: activation histograms, gradient histograms, and the update-to-data ratio. ",
          "start": 5211,
          "end": 6957,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Interpreting Activation Histograms (Checking for saturation)",
            "Checking Gradient Distributions",
            "Update-to-Data Ratio (Ideal: ~1e-3)"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the 'Update to Data' ratio for logging.",
              "template": "# lr is learning rate, grad is gradient, data is parameter value\nupdate = lr * grad.std()\ndata = param.std()\nratio = update / ___\nlog_ratio = ratio.log10()",
              "solution": "data",
              "hints": [
                "We want the ratio of the update size to the parameter size."
              ]
            },
            {
              "type": "quiz",
              "instruction": "If your Update-to-Data ratio is around -3.0 (on a log10 scale), what does this indicate?",
              "options": [
                "The updates are roughly 1/1000th the size of the weights. This is a good sweet spot.",
                "The updates are way too large; the model is exploding.",
                "The updates are essentially zero; the model isn't learning."
              ],
              "solution": "The updates are roughly 1/1000th the size of the weights. This is a good sweet spot.",
              "hints": [
                "10^-3 is 0.001."
              ]
            }
          ]
        }
      ]
    }, 
    {
      "id": "course_makemore_backprop",
      "title": "Makemore: Becoming a Backprop Ninja",
      "thumbnail": "assets/makemore-backprop-thumbnail.jpg",
      "description": "De-mystify deep learning by manually implementing backpropagation from scratch. Move beyond 'loss.backward()' to understand tensor-level gradients, matrix calculus, and analytical simplifications for Cross Entropy and Batch Normalization.",
      "sequence_order": 7,
      "chapters": [
        {
          "id": "makemore_bp_ch1",
          "title": "The Leaky Abstraction of Backprop",
          "video_id": "q8SA3rM6ckI",
          "description": "We establish why manual backpropagation is a crucial skill for debugging neural networks. We set up the Multi-Layer Perceptron (MLP) architecture with Batch Normalization that we will be dissecting.",
          "start": 0,
          "end": 781,
          "xp_reward": 30,
          "key_learning_outcomes": [
            "Historical context of manual backprop (pre-Autograd)",
            "The concept of 'Leaky Abstractions' in deep learning",
            "Setting up the MLP forward pass for manual differentiation"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why does the instructor consider Backpropagation a 'Leaky Abstraction'?",
              "options": [
                "Because you can easily shoot yourself in the foot (e.g., vanishing gradients, dead neurons) if you don't understand the internals.",
                "Because it leaks memory if not handled correctly in C++.",
                "Because it reveals the private data of the training set."
              ],
              "solution": "Because you can easily shoot yourself in the foot (e.g., vanishing gradients, dead neurons) if you don't understand the internals.",
              "hints": [
                "Think about debugging issues like saturated tanh or exploding gradients."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch2",
          "title": "Backprop: Loss to Probabilities",
          "video_id": "q8SA3rM6ckI",
          "description": "We begin the manual backward pass at the very end of the graph. We derive gradients for the Negative Log Likelihood loss, log probabilities, and handling shapes/broadcasting during the backward pass.",
          "start": 781,
          "end": 2011,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Gradient of Mean Loss (-1/N)",
            "Backpropagating through `log(x)` (1/x)",
            "Handling tensor shapes during gradient assignment"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "Calculate the gradient of the loss with respect to log-probabilities `dlogprobs` for the correct indices.",
              "template": "# n is batch size\n# We only care about the indices specified by target 'Yb'\ndlogprobs[range(n), Yb] = ___ * (1.0/n)",
              "solution": "-1",
              "hints": [
                "The loss is the NEGATIVE log likelihood."
              ]
            },
            {
              "type": "code",
              "instruction": "Implement the backward pass for the log operation `logprobs = probs.log()`.",
              "template": "# dlogprobs is the gradient flowing in\n# d/dx log(x) = 1/x\ndprobs = (1.0 / ___) * dlogprobs",
              "solution": "probs",
              "hints": [
                "Multiply the local derivative (1/input) by the global gradient."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch3",
          "title": "Backprop: Broadcasting & Linear Layers",
          "video_id": "q8SA3rM6ckI",
          "description": "We tackle the complexity of broadcasting in reverse. If a dimension is replicated (broadcasted) in the forward pass, it must be summed in the backward pass. We also derive the gradients for Matrix Multiplication.",
          "start": 2011,
          "end": 3223,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Broadcasting rule: Forward Copy -> Backward Sum",
            "Backpropagating through Matrix Multiplication",
            "Matching shapes to determine transpositions"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "If `counts_sum` (shape 32x1) was broadcasted to shape (32x27) during division in the forward pass, how do we calculate its gradient `dcounts_sum`?",
              "options": [
                "Sum the incoming gradient `dcounts` across the broadcasted dimension (dim 1).",
                "Replicate the incoming gradient.",
                "Take the mean of the incoming gradient."
              ],
              "solution": "Sum the incoming gradient `dcounts` across the broadcasted dimension (dim 1).",
              "hints": [
                "The variable was used multiple times (once for each column), so we accumulate the gradients."
              ]
            },
            {
              "type": "parsons",
              "instruction": "Determine the gradient `dh` for the expression `logits = h @ W2 + b2`. `dlogits` is (32, 27), `W2` is (64, 27). `dh` must be (32, 64).",
              "solution": "dh = dlogits @ W2.T",
              "lines": [
                "dh = dlogits @ W2.T",
                "dh = dlogits.T @ W2",
                "dh = W2 @ dlogits"
              ],
              "hints": [
                "Align the inner dimensions: (32, 27) @ (27, 64) results in (32, 64)."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch4",
          "title": "Backprop: Tanh & BatchNorm Decomposition",
          "video_id": "q8SA3rM6ckI",
          "description": "We backpropagate through the Tanh activation function and begin dissecting the Batch Normalization layer into its atomic operations (mean, variance, standardization) to calculate gradients step-by-step.",
          "start": 3223,
          "end": 3912,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Gradient of Tanh: `1 - t**2`",
            "Backpropagating through `max()` and `indices`",
            "Decomposing Batch Norm into differentiable steps"
          ],
          "tasks": [
            {
              "type": "code",
              "instruction": "Calculate the gradient for the Tanh activation `h = h_preact.tanh()`.",
              "template": "# h is the output of the tanh function\n# d/dx tanh(x) = 1 - tanh(x)^2\ndh_preact = (1.0 - ___**2) * dh",
              "solution": "h",
              "hints": [
                "The derivative can be expressed in terms of the output `h`."
              ]
            },
            {
              "type": "gap_fill",
              "instruction": "When backpropagating through `max()`, the gradient is routed ONLY to the indices that achieved the max value. We use `one_hot` to create a mask.",
              "template": "# dlogit_maxes flows only to the max indices\ndlogits += F.one_hot(indices, num_classes=27) * ___",
              "solution": "dlogit_maxes",
              "hints": [
                "Multiply the mask by the incoming gradient."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch5",
          "title": "Bessel's Correction & Variance",
          "video_id": "q8SA3rM6ckI",
          "description": "We dive into the subtle details of variance calculation, specifically Bessel's Correction (dividing by N-1 vs N), and finish backpropagating through the complex chain of Batch Norm operations.",
          "start": 3912,
          "end": 5191,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Bessel's Correction (Unbiased estimator)",
            "Backpropagating through variance calculation",
            "Handling branching paths in computation graphs"
          ],
          "tasks": [
            {
              "type": "quiz",
              "instruction": "Why does the instructor use `1/(n-1)` instead of `1/n` for variance calculation?",
              "options": [
                "It is the unbiased estimator for population variance (Bessel's correction).",
                "It prevents division by zero.",
                "It makes the tensor shapes align better."
              ],
              "solution": "It is the unbiased estimator for population variance (Bessel's correction).",
              "hints": [
                "This correction matters when sample sizes are small."
              ]
            },
            {
              "type": "code",
              "instruction": "Backpropagate through the centering operation `diff = x - mean`.",
              "template": "# d_diff flows back to x and mean\ndx = d_diff\n# Because mean is broadcasted (replicated) across the batch, we sum\ndmean = -d_diff.sum(___, keepdim=True)",
              "solution": "0",
              "hints": [
                "Sum across the batch dimension (0)."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch6",
          "title": "Analytical Gradients: Cross Entropy",
          "video_id": "q8SA3rM6ckI",
          "description": "We realize that backpropagating through atomic loss operations is inefficient. We derive the analytical gradient for the Softmax + Cross Entropy combined layer, resulting in a significantly simpler and faster formula.",
          "start": 5191,
          "end": 5797,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Analytical simplification of Softmax gradient",
            "The `softmax(logits) - target` formula",
            "Intuition of 'Push and Pull' forces in gradients"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Implement the efficient analytical gradient for Cross Entropy Loss.",
              "solution": "dlogits = F.softmax(logits, 1)\ndlogits[range(n), Yb] -= 1\ndlogits /= n",
              "lines": [
                "dlogits /= n",
                "dlogits[range(n), Yb] -= 1",
                "dlogits = F.softmax(logits, 1)"
              ],
              "hints": [
                "Calculate softmax probabilities first.",
                "Subtract 1 from the correct label indices.",
                "Normalize by batch size."
              ]
            },
            {
              "type": "quiz",
              "instruction": "What is the sum of the gradients in `dlogits` for any single example?",
              "options": [
                "Zero",
                "One",
                "It depends on the loss."
              ],
              "solution": "Zero",
              "hints": [
                "The forces of pushing down incorrect classes and pulling up the correct class equalize."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch7",
          "title": "Analytical Gradients: Batch Norm",
          "video_id": "q8SA3rM6ckI",
          "description": "Similar to Cross Entropy, we replace the messy atomic backprop of Batch Norm with a mathematically derived, streamlined equation. ",
          "start": 5797,
          "end": 6602,
          "xp_reward": 100,
          "key_learning_outcomes": [
            "Analytical derivative of Batch Normalization",
            "Computational efficiency of fused kernels",
            "Verifying manual gradients against PyTorch"
          ],
          "tasks": [
            {
              "type": "gap_fill",
              "instruction": "The analytical gradient for Batch Norm involves creating a simplified expression for `dh_preact`. This avoids creating intermediate buffers for mean and variance during the ___ pass.",
              "solution": "backward",
              "hints": [
                "We are optimizing the gradient calculation step."
              ]
            },
            {
              "type": "code",
              "instruction": "Call the custom comparison function to verify your manual gradients.",
              "template": "# cmp(manual_name, manual_tensor, pytorch_tensor)\ncmp('h_preact', dh_preact, ___)",
              "solution": "h_preact.grad",
              "hints": [
                "You compare against the `.grad` attribute populated by PyTorch's autograd."
              ]
            }
          ]
        },
        {
          "id": "makemore_bp_ch8",
          "title": "The Grand Loop: Putting It All Together",
          "video_id": "q8SA3rM6ckI",
          "description": "We assemble the complete training loop, replacing `loss.backward()` entirely with our manual implementations. We verify that the network trains just as well as before.",
          "start": 6602,
          "end": 6923,
          "xp_reward": 50,
          "key_learning_outcomes": [
            "Replacing Autograd with manual backprop",
            "Structure of a rigorous training loop",
            "Verification of correctness"
          ],
          "tasks": [
            {
              "type": "parsons",
              "instruction": "Order the steps of the manual training loop.",
              "solution": "forward_pass()\n# Manual Backprop\nbackprop_cross_entropy()\nbackprop_layers()\noptimizer_step()",
              "lines": [
                "optimizer_step()",
                "forward_pass()",
                "backprop_cross_entropy()",
                "backprop_layers()"
              ],
              "hints": [
                "You must compute the loss (forward) before you can derive gradients (backward)."
              ]
            }
          ]
        }
      ]
    }
 
 

  ]
}